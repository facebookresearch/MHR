{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["rSRkfFTke_b7"],"authorship_tag":"ABX9TyOsSSDbZ5rFsOcSUncl+t5f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e871456d9a634f9187164783065f8f38":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47fbe8d431754cd388b9436222dae7b1","IPY_MODEL_19f3e15598c14264b43b6f1d8744c4b9"],"layout":"IPY_MODEL_8797659f8b3e400b93b6948da6e4ff17"}},"47fbe8d431754cd388b9436222dae7b1":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5c36c0cb53d64353ab937ec996bfd0ce","IPY_MODEL_5248565af43142c597da644cf7920761","IPY_MODEL_91cf88dddde74703b0bb1b72fd008b3a"],"layout":"IPY_MODEL_d3923bd0b04348f392432ec1cc74ad69"}},"19f3e15598c14264b43b6f1d8744c4b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac694e18374a4c9f9ddc697aa229eb08","placeholder":"​","style":"IPY_MODEL_c833a9bfa4f24bbe86590833d3c6d9d2","value":"\n        <div style=\"font-family: Arial, sans-serif;\">\n            <div style=\"display: flex; justify-content: space-between;\">\n                <div style=\"width: 48%;\">\n                    <div style=\"margin-bottom: 10px;\">\n                        <strong>Parameter Name:</strong><br>\n                        <span style=\"color: #0066cc; font-size: 14px;\">root_tx</span>\n                    </div>\n                    <div style=\"margin-bottom: 10px;\">\n                        <strong>Value Limits:</strong><br>\n                        <span style=\"color: #666;\">Min: -10.0000</span><br>\n                        <span style=\"color: #666;\">Max: 10.0000</span>\n                    </div>\n                </div>\n                <div style=\"width: 48%;\">\n                    <div style=\"margin-bottom: 10px;\">\n                        <strong>Current Value:</strong><br>\n                        <span style=\"color: #ff6600; font-size: 16px; font-weight: bold;\">0.0000</span>\n                    </div>\n                    <div style=\"margin-bottom: 10px;\">\n                        <strong>Associated Joints:</strong><br>\n                        <div style=\"color: #009900; font-size: 12px;\">\n                              • root\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n        "}},"8797659f8b3e400b93b6948da6e4ff17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"98%"}},"5c36c0cb53d64353ab937ec996bfd0ce":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["root_tx","root_ty","root_tz","root_rx","root_ry","root_rz","spine0_rx_flexible","spine_twist0","spine0_ry_flexible","spine_lean0","spine0_rz_flexible","spine_bend0","spine1_rx_flexible","spine_twist1","spine1_ry_flexible","spine_lean1","spine1_rz_flexible","spine_bend1","spine2_rx_flexible","spine2_ry_flexible","spine2_rz_flexible","spine3_rx_flexible","spine3_ry_flexible","spine3_rz_flexible","neck_twist","neck_lean","neck_bend","head_twist","head_lean","head_bend","r_clavicle_rx","r_clavicle_ry","r_clavicle_rz","r_uparm_twist","r_uparm_ry","r_uparm_rz","r_elbow_bend","r_lowarm_twist","r_wrist_ry","r_wrist_rz","l_clavicle_rx","l_clavicle_ry","l_clavicle_rz","l_uparm_twist","l_uparm_ry","l_uparm_rz","l_elbow_bend","l_lowarm_twist","l_wrist_ry","l_wrist_rz","r_upleg_twist","r_upleg_ry","r_upleg_rz","r_knee_bend","r_lowleg_twist","r_foot_bend","r_foot_lean0","r_foot_lean1","r_ball_bend","l_upleg_twist","l_upleg_ry","l_upleg_rz","l_knee_bend","l_lowleg_twist","l_foot_bend","l_foot_lean0","l_foot_lean1","l_ball_bend","r_thumb0_ry","r_thumb0_rz","r_thumb1_rx","r_thumb1_ry","r_thumb1_rz","r_thumb2_rz","r_thumb3_rz","r_index1_ry","r_ring1_ry","r_pinky1_ry","r_middle1_ry","r_index1_rz","r_index2_rz","r_index3_rz","r_middle1_rz","r_middle2_rz","r_middle3_rz","r_ring1_rz","r_ring2_rz","r_ring3_rz","r_pinky1_rz","r_pinky2_rz","r_pinky3_rz","r_index1_rx","r_ring1_rx","r_pinky1_rx","r_middle1_rx","l_thumb0_ry","l_thumb0_rz","l_thumb1_rx","l_thumb1_ry","l_thumb1_rz","l_thumb2_rz","l_thumb3_rz","l_index1_ry","l_ring1_ry","l_pinky1_ry","l_middle1_ry","l_index1_rz","l_index2_rz","l_index3_rz","l_middle1_rz","l_middle2_rz","l_middle3_rz","l_ring1_rz","l_ring2_rz","l_ring3_rz","l_pinky1_rz","l_pinky2_rz","l_pinky3_rz","l_index1_rx","l_ring1_rx","l_pinky1_rx","l_middle1_rx","l_foot_ry_flexible","l_subtalar_rz_flexible","l_talocrural_rx_flexible","l_ball_rx_flexible","r_foot_ry_flexible","r_subtalar_rz_flexible","r_talocrural_rx_flexible","r_ball_rx_flexible","spine_length_flexible","neck_length_flexible","shoulder_width_flexible","arm_length_flexible","hip_width_flexible","leg_length_flexible","scale_eye_width","scale_eye_height","scale_eye_depth","scale_spine_length","scale_neck_length","scale_shoulder_width","scale_uparms","scale_lowarms","scale_r_hands","scale_l_hands","scale_hip_width","scale_hip_height","scale_hip_depth","scale_uplegs","scale_lowlegs","scale_knee_knock","scale_ankle_height","scale_foot_length","scale_r_index1_length","scale_r_middle1_length","scale_r_ring1_length","scale_r_pinky1_length","scale_r_thumb1_length","scale_r_index1_offset","scale_r_middle1_offset","scale_r_ring1_offset","scale_r_pinky1_offset","scale_r_thumb1_offset","scale_r_index2_length","scale_r_middle2_length","scale_r_ring2_length","scale_r_pinky2_length","scale_r_thumb2_length","scale_r_index3_length","scale_r_middle3_length","scale_r_ring3_length","scale_r_pinky3_length","scale_r_thumb3_length","scale_r_index_null_tx","scale_r_middle_null_tx","scale_r_ring_null_tx","scale_r_pinky_null_tx","scale_r_thumb_null_tx","scale_l_index1_length","scale_l_middle1_length","scale_l_ring1_length","scale_l_pinky1_length","scale_l_thumb1_length","scale_l_index1_offset","scale_l_middle1_offset","scale_l_ring1_offset","scale_l_pinky1_offset","scale_l_thumb1_offset","scale_l_index2_length","scale_l_middle2_length","scale_l_ring2_length","scale_l_pinky2_length","scale_l_thumb2_length","scale_l_index3_length","scale_l_middle3_length","scale_l_ring3_length","scale_l_pinky3_length","scale_l_thumb3_length","scale_l_index_null_tx","scale_l_middle_null_tx","scale_l_ring_null_tx","scale_l_pinky_null_tx","scale_l_thumb_null_tx"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Parameter:","description_tooltip":null,"disabled":false,"index":0,"layout":"IPY_MODEL_137f98e86033424c8b92b738c57b468d","style":"IPY_MODEL_7612137e9bb544a68da0e4530bed3477"}},"5248565af43142c597da644cf7920761":{"model_module":"@jupyter-widgets/controls","model_name":"FloatSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"FloatSliderView","continuous_update":false,"description":"Value:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_bb6b6c9d61b845bb81d1dcf1ebac5bfe","max":10,"min":-10,"orientation":"horizontal","readout":true,"readout_format":".2f","step":0.01,"style":"IPY_MODEL_7fba24baffee436b8043aa7c07b4d689","value":0}},"91cf88dddde74703b0bb1b72fd008b3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4780f2f6583d428a9bf34010f266a8e0","IPY_MODEL_439059252f494013ad1f81eda077f02d"],"layout":"IPY_MODEL_fbd5c17a962542f0ad1d59d5649cb4bf"}},"d3923bd0b04348f392432ec1cc74ad69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":"1px solid #ccc","bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":"10px","right":null,"top":null,"visibility":null,"width":"40%"}},"ac694e18374a4c9f9ddc697aa229eb08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":"0px solid #ccc","bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":"170px","justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":"auto","overflow_x":null,"overflow_y":null,"padding":"20px","right":null,"top":null,"visibility":null,"width":"60%"}},"c833a9bfa4f24bbe86590833d3c6d9d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"137f98e86033424c8b92b738c57b468d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"95%"}},"7612137e9bb544a68da0e4530bed3477":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"bb6b6c9d61b845bb81d1dcf1ebac5bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"95%"}},"7fba24baffee436b8043aa7c07b4d689":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial","handle_color":null}},"4780f2f6583d428a9bf34010f266a8e0":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"warning","description":"Reset Current Parameter","disabled":false,"icon":"","layout":"IPY_MODEL_6a8777432a1f46d7b39a83c009585b13","style":"IPY_MODEL_4719a95c0a47472782125a3e2f483c16","tooltip":""}},"439059252f494013ad1f81eda077f02d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"danger","description":"Reset All","disabled":false,"icon":"","layout":"IPY_MODEL_48e2110ba9764fa0ad29a623ae7a0895","style":"IPY_MODEL_49abd3dd96a940e38da25af0ebd1e951","tooltip":""}},"fbd5c17a962542f0ad1d59d5649cb4bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":"space-between","justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8777432a1f46d7b39a83c009585b13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"48%"}},"4719a95c0a47472782125a3e2f483c16":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"48e2110ba9764fa0ad29a623ae7a0895":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"48%"}},"49abd3dd96a940e38da25af0ebd1e951":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Welcome to MHR Visualization!\n","This basic tutorial will show you how MHR model looks like, the kinematics and the shape space of the model.\n","\n","---\n","\n","## How to run this tutorial\n"," - Run the cell group **Preparation**.\n"," - Next, run any cell that interests you afterwards.\n","\n","## Known issue about the visualization\n","If you use Chrome and have two visualizations visible in one Chrome tab, there will be flickering. Try to scroll up and down or expand cells or add empty cells to make sure there is only one visualization visible in the tab to avoid this problem."],"metadata":{"id":"Qiymn9PfdAEj"}},{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"rSRkfFTke_b7"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"rcNzOyiqA-8p","executionInfo":{"status":"ok","timestamp":1763524671347,"user_tz":-60,"elapsed":5374,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"cellView":"form"},"outputs":[],"source":["#@title Install dependencies\n","%%capture\n","!pip3 install torch scenepic gdown trimesh"]},{"cell_type":"code","source":["#@title Download and load the MHR model\n","import gdown\n","import os\n","import torch\n","\n","MHR_MODEL_PATH = \"/content/models/mhr_demo.torchscript\"\n","if not os.path.exists(MHR_MODEL_PATH):\n","  os.makedirs(\"/content/models\", exist_ok=True)\n","  file_id = \"1z8bH2iXyXI8E7Ar5d8abz1yYSwXVPPg-\"\n","  output_path = MHR_MODEL_PATH\n","  gdown.download(id=file_id, output=output_path, quiet=False)\n","else:\n","  print(\"Model already downloaded. Directly load the downloaded model.\")\n","\n","scripted_mhr_model = torch.jit.load(MHR_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"UM-Mt17gBNuc","outputId":"a51e62a5-8b21-4388-f880-f320a1a3f350","executionInfo":{"status":"ok","timestamp":1763524671963,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"collapsed":true},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model already downloaded. Directly load the downloaded model.\n"]}]},{"cell_type":"code","source":["#@title Visualization tool\n","\"\"\"\n","ScenePic 3D Visualization Utilities\n","\n","This module provides a high-level Python wrapper around the ScenePic library for creating\n","interactive 3D visualizations of computer vision and robotics assets. It simplifies the\n","process of visualizing complex 3D data including meshes, point clouds, line set animations,\n","and coordinate frames in both Jupyter notebook environments and standalone HTML files. It\n","is designed to be used for FAST debugging purposes during development and research.\n","\n","Key Features:\n","    • Multi-asset visualization: Support for meshes, point clouds, line sets, coordinate frames\n","    • IDE integration: Can be used in Bento\n","    • Animation support: Multi-frame temporal data with timeline controls\n","    • Flexible rendering: Automatic and manual camera positioning, customizable lighting\n","    • Interactive output: Mouse navigation (rotation, zoom, pan) in browser\n","    • Export capabilities: Self-contained HTML files for sharing and archiving\n","    • Color management: Automatic rainbow colormaps or custom color schemes\n","    • Label support: Text labels for point cloud data visualization\n","\n","Components:\n","    ScenepicVisualization: Main visualization class providing the high-level interface\n","    Helper functions and type alias: Color validation, normalization, and utility functions\n","\n","Typical Workflow:\n","    1. Create a ScenepicVisualization instance\n","    2. Add 3D assets using add_meshes(), add_point_clouds(), add_line_sets(), or add_coordinate_frames()\n","    3. Optionally customize lighting, camera position, or colors\n","    4. Display in Jupyter with show() or save to HTML with save_to_html()\n","\n","Example Usage:\n","    ```python\n","    import numpy as np\n","    from xrcia.projects.tracked_assets.core.visualization.scenepic_visualization import ScenepicVisualization\n","\n","    # Create visualization instance\n","    viz = ScenepicVisualization()\n","\n","    # Add some sample data\n","    points = np.random.rand(100, 3)\n","    viz.add_point_clouds([[points]], point_labels=[['Point ' + str(i) for i in range(100)]])\n","\n","    # Add coordinate frame at origin\n","    origins = [[[0, 0, 0]]]\n","    orientations = [[[np.eye(3)]]]\n","    viz.add_coordinate_frames(origins, orientations)\n","\n","    # Display in notebook\n","    viz.show()\n","\n","    # Or save to file\n","    viz.save_to_html(\"visualization.html\")\n","    ```\n","\n","Dependencies:\n","    • scenepic: Core 3D visualization library with WebGL rendering\n","    • trimesh: Mesh processing and validation\n","    • numpy: Numerical computation and array handling\n","    • matplotlib: Color management and colormaps\n","    • IPython: Bento display integration\n","\n","Units and Coordinate System:\n","    • All measurements are assumed to be in METERS\n","    • Uses right-handed coordinate system (X=right, Y=up, Z=forward)\n","    • Coordinate frames follow standard RGB coloring (X=Red, Y=Green, Z=Blue)\n","\n","Performance Considerations:\n","    • Large datasets may impact browser performance\n","    • Multi-frame animations require more memory and processing\n","    • Point cloud instancing is optimized for performance\n","    • HTML export includes all data inline (no external dependencies)\n","\n","Error Handling:\n","    • Comprehensive input validation with descriptive error messages\n","    • Type checking for data structures and color formats\n","    • Frame count consistency validation across asset types\n","    • Graceful handling of edge cases (empty data, single frames, etc.)\n","\n","Browser Compatibility:\n","    • Requires modern browser with WebGL support\n","    • Tested on Chrome, Firefox, Safari, Edge\n","    • Mobile browser support varies based on device capabilities\n","\n","Meta Internal Usage:\n","    This module is designed for use within Meta's computer vision and robotics projects,\n","    particularly for visualizing tracked assets, motion capture data, and 3D scene\n","    understanding results. It integrates with internal tooling and Bento notebook environments.\n","\n","TODO(T238674328):\n","    • Support mesh texture\n","    • Support untracked sequence of data\n","\"\"\"\n","\n","from typing import Any, Union\n","\n","import IPython\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import scenepic as sp\n","import trimesh\n","\n","# Custom type definition for mesh colors configuration\n","# Supports n x 3 arrays of both integers and floats\n","MeshMonoColors = Union[\n","    # Per-mesh colors\n","    np.ndarray[tuple[int], np.dtype[np.uint8]],  # 3 uint8 (0-255)\n","    np.ndarray[tuple[int], np.dtype[np.int32]],  # 3 int32 (0-255)\n","    np.ndarray[tuple[int], np.dtype[np.int64]],  # 3 int64 (0-255)\n","    np.ndarray[tuple[int], np.dtype[np.float32]],  # 3 float32 (0.0-1.0)\n","    np.ndarray[tuple[int], np.dtype[np.float64]],  # 3 float64 (0.0-1.0)\n","]\n","MeshPervertexColors = Union[\n","    # Per-vertex colors\n","    np.ndarray[tuple[int, int], np.dtype[np.uint8]],  # v x 3 uint8 (0-255)\n","    np.ndarray[tuple[int, int], np.dtype[np.int32]],  # v x 3 int32 (0-255)\n","    np.ndarray[tuple[int, int], np.dtype[np.int64]],  # v x 3 int64 (0-255)\n","    np.ndarray[tuple[int, int], np.dtype[np.float32]],  # v x 3 float32 (0.0-1.0)\n","    np.ndarray[tuple[int, int], np.dtype[np.float64]],  # v x 3 float64 (0.0-1.0)\n","]\n","# Define colors based on xrcia.projects.tracked_assets.core.visualization.image_draw.Color, but with float32 dtype\n","_WHITE: MeshMonoColors = np.array([1.0, 1.0, 1.0])\n","_BLACK: MeshMonoColors = np.array([0.0, 0.0, 0.0])\n","_LIGHT_GRAY: MeshMonoColors = np.array([0.7, 0.7, 0.7])\n","_DARK_GRAY: MeshMonoColors = np.array([0.3, 0.3, 0.3])\n","\n","\n","class ScenepicVisualization:\n","    \"\"\"\n","    A wrapper around the ScenePic library to facilitate 3D visualization of various assets.\n","\n","    This class provides a high-level interface for creating interactive 3D visualizations\n","    using the ScenePic library. It supports multiple types of 3D assets including meshes,\n","    point clouds, line sets, and coordinate frames. The visualization can be displayed\n","    in Bento or saved as standalone HTML files.\n","\n","    Features:\n","        - Multi-frame animation support for temporal data\n","        - Automatic color generation using rainbow colormaps\n","        - Flexible camera positioning (automatic or manual)\n","        - Support for mesh, point cloud, line set, and coordinate frame visualization\n","        - Customizable shading and lighting\n","        - Label support for point clouds\n","        - Interactive HTML output for web viewing\n","\n","    * Important Note: This class assumes METERS as the unit of measurement for all assets.\n","\n","    Example:\n","        ```python\n","        # Create a visualization\n","        viz = ScenepicVisualization()\n","\n","        # Add meshes (single frame or multi-frame)\n","        viz.add_meshes(meshes_list)\n","\n","        # Add point clouds with labels (all visible by default)\n","        viz.add_point_clouds(point_clouds_list, point_labels=labels)\n","\n","        # Add line sets with individual visibility control\n","        viz.add_line_sets(start_points, end_points, hide_line_sets=[False, True, False])\n","\n","        # Add coordinate frames (all visible by default)\n","        viz.add_coordinate_frames(origins, orientations)\n","\n","        # Display or save\n","        viz.show()\n","        viz.save_to_html(\"output.html\")\n","        ```\n","    \"\"\"\n","\n","    def __init__(self) -> None:\n","        \"\"\"\n","        Initialize a new ScenepicVisualization instance.\n","\n","        Creates a new ScenePic scene with default camera, lighting, and shading settings.\n","        All asset types (meshes, point clouds, line sets, coordinate frames) are initially\n","        disabled and will be enabled when assets are added.\n","\n","        The scene bounding box is automatically calculated as assets are added, and the\n","        camera will be positioned automatically unless manually set.\n","\n","        Default Settings:\n","            - White background with standard ambient and directional lighting\n","            - Automatic camera positioning based on scene bounding box\n","            - Rainbow colormap for automatically generated colors\n","            - Point size: 0.01 units\n","            - Line thickness: 0.01 units for line set visualization\n","            - Coordinate frame size: 0.1 units\n","            - All asset types visible by default\n","        \"\"\"\n","        self.scene: sp.Scene = sp.Scene()\n","\n","        self.num_meshes_per_frame: int = 0\n","        self.meshes: list[list[trimesh.Trimesh]] = []\n","        self.mesh_names: list[str] = []\n","        self.mesh_colors: list[MeshMonoColors | MeshPervertexColors] = []\n","        self.mesh_opacity: list[float] = []\n","        self.mesh_vertex_uvs: (\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]] | None] | None\n","        ) = None\n","        self.mesh_texture_images: (\n","            list[np.ndarray[tuple[int, int, int], np.dtype[np.uint8]] | None] | None\n","        ) = None\n","\n","        self.num_point_clouds_per_frame: int = 0\n","        self.point_clouds: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ] = []\n","        self.point_cloud_names: list[str] = []\n","        self.point_cloud_colors: list[MeshMonoColors | MeshPervertexColors] = []\n","        self.point_cloud_opacity: list[float] = []\n","        self.point_size: float = 0.01\n","        self.point_labels: list[list[str]] = []\n","        self.point_label_opacity: list[float] = []\n","        self.label_color: MeshMonoColors | MeshPervertexColors = _BLACK\n","        self.point_label_offset: float = 0.01\n","        self.label_size_in_pixel: int = 20\n","\n","        self.num_line_sets_per_frame: int = 0\n","        self.start_points: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ] = []\n","        self.end_points: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ] = []\n","        self.line_set_names: list[str] = []\n","        self.line_set_colors: list[MeshMonoColors | MeshPervertexColors] = []\n","        self.line_set_opacity: list[float] = []\n","        self.line_type: str = \"thickline\"\n","        self.line_start_thickness: float = 0.01\n","\n","        self.num_coordinate_frames_per_frame: int = 0\n","        self.coordinate_frame_origins: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ] = []\n","        self.coordinate_frame_orientations: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ] = []\n","        self.coordinate_frame_names: list[str] = []\n","        self.coordinate_frame_opacity: list[float] = []\n","        self.frame_size: float = 0.1\n","\n","        self.scene_bbox: np.ndarray[tuple[int, int], np.dtype[np.float32]] = np.zeros(\n","            (2, 3), dtype=np.float32\n","        )\n","        self.scene_bbox[0] = -np.inf * np.ones(3)\n","        self.scene_bbox[1] = np.inf * np.ones(3)\n","\n","        # Initialize with default camera parameters using simplified constructor\n","        self.camera: sp.Camera = sp.Camera(\n","            center=np.array([0.0, 0.0, 3.0], dtype=np.float32),\n","            look_at=np.array([0.0, 0.0, 0.0], dtype=np.float32),\n","            fov_y_degrees=30.0,\n","            aspect_ratio=1.0,\n","            far_crop_distance=20.0,\n","            near_crop_distance=0.01,\n","        )\n","        self.camera_is_manually_set = False\n","\n","        # Set the default background color to white.\n","        self.shading = sp.Shading(\n","            bg_color=_WHITE,\n","            ambient_light_color=_LIGHT_GRAY,\n","            directional_light_color=_DARK_GRAY,\n","            directional_light_dir=np.array([2, 1, 2]),\n","        )\n","\n","    def add_meshes(\n","        self,\n","        meshes: list[list[trimesh.Trimesh]],\n","        mesh_names: list[str] | None = None,\n","        mesh_colors: list[MeshMonoColors | MeshPervertexColors | None] | None = None,\n","        mesh_opacity: list[float] | None = None,\n","        mesh_vertex_uvs: list[np.ndarray[tuple[int, int], np.dtype[np.float32]] | None]\n","        | None = None,\n","        mesh_texture_images: list[\n","            np.ndarray[tuple[int, int, int], np.dtype[np.uint8]] | None\n","        ]\n","        | None = None,\n","    ) -> None:\n","        \"\"\"\n","        Add meshes to the scene for visualization.\n","\n","        Meshes can be provided as a single frame or multiple frames for animation.\n","        Each mesh will be rendered with customizable colors and names. Optionally,\n","        meshes can be textured using UV coordinates and texture images.\n","\n","        Args:\n","            meshes: List of lists containing Trimesh objects. Each inner list represents\n","                   a frame, and each Trimesh is a mesh in that frame. For single frame\n","                   data, provide a list containing one list of meshes.\n","            mesh_names: Optional names for each mesh. If not provided, names will be\n","                       automatically generated as \"mesh_0\", \"mesh_1\", etc.\n","            mesh_colors: Optional colors for each mesh. Can be per-mesh uniform colors,\n","                        per-vertex colors, or None for individual meshes. If not provided,\n","                        colors will be automatically generated using a rainbow colormap.\n","                        For mixed rendering with textures, individual elements can be None\n","                        for textured meshes while providing colors for non-textured meshes.\n","            mesh_opacity: Optional list of opacity values for specific meshes. Each value\n","                          should be between 0.0 (fully transparent) and 1.0 (fully opaque).\n","                          If provided, must have the same length as the number of meshes per frame.\n","                          If not provided, all meshes will be fully opaque (opacity=1.0) by default.\n","            mesh_vertex_uvs: Optional list of UV coordinate arrays for per-vertex texture mapping. Each array\n","                     should have shape (N, 2) where N is the number of vertices in the corresponding\n","                     mesh. UV coordinates should be in range [0, 1]. Individual elements can be None\n","                     for non-textured meshes in mixed rendering scenarios. If provided, must have the\n","                     same length as meshes and be paired with mesh_texture_images.\n","            mesh_texture_images: Optional list of texture image arrays. Each array should be\n","                                in RGB format with shape (H, W, 3) and uint8 values [0, 255].\n","                                If provided, must have the same length as meshes and be paired\n","                                with mesh_uvs.\n","\n","        Raises:\n","            ValueError: If meshes are not in the correct list of lists format, or if UV\n","                       coordinates and texture images are not properly paired.\n","\n","        Note:\n","            - All frames must contain the same number of meshes\n","            - Mesh colors can be uniform (one color per mesh) or per-vertex\n","            - When textures are provided, vertex colors are ignored\n","            - UV coordinates and texture images must be provided together\n","            - Automatically updates the scene bounding box\n","            - Individual mesh visibility can be controlled via the hide_meshes parameter\n","        \"\"\"\n","        self.meshes, self.num_meshes_per_frame = self._validate_input_is_list_of_lists(\n","            meshes, \"Meshes\"\n","        )\n","\n","        self.mesh_names = (\n","            mesh_names\n","            if mesh_names is not None\n","            else [f\"mesh_{i}\" for i in range(self.num_meshes_per_frame)]\n","        )\n","\n","        self.mesh_opacity = (\n","            mesh_opacity\n","            if mesh_opacity is not None\n","            else [1.0] * self.num_meshes_per_frame\n","        )\n","\n","        self._setup_mesh_texture_and_vertex_color(\n","            mesh_colors, mesh_vertex_uvs, mesh_texture_images\n","        )\n","\n","        # Get the bounding box for the added meshes.\n","        max_mesh_corner = -np.inf * np.ones(3)\n","        min_mesh_corner = np.inf * np.ones(3)\n","        for one_frame_meshes in self.meshes:\n","            for mesh in one_frame_meshes:\n","                vertices = mesh.vertices\n","                max_mesh_corner = np.maximum(max_mesh_corner, np.max(vertices, axis=0))\n","                min_mesh_corner = np.minimum(min_mesh_corner, np.min(vertices, axis=0))\n","\n","        # Update the scene bounding box according to the bounding box of all the added meshes.\n","        self.scene_bbox[0] = np.maximum(self.scene_bbox[0], max_mesh_corner)\n","        self.scene_bbox[1] = np.minimum(self.scene_bbox[1], min_mesh_corner)\n","\n","    def add_point_clouds(\n","        self,\n","        point_clouds: list[list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]],\n","        point_cloud_names: list[str] | None = None,\n","        point_cloud_colors: list[MeshMonoColors | MeshPervertexColors | None]\n","        | None = None,\n","        point_cloud_opacity: list[float] | None = None,\n","        point_size: float = 0.01,\n","        point_labels: list[list[str]] | None = None,\n","        point_label_opacity: list[float] | None = None,\n","        label_color: MeshMonoColors | MeshPervertexColors = _BLACK,\n","        label_offset: float = 0.01,\n","        label_size_in_pixel: int = 20,\n","    ) -> None:\n","        \"\"\"\n","        Add point clouds to the scene for visualization.\n","\n","        Point clouds are rendered as instanced spheres with customizable size and colors.\n","        Optional text labels can be attached to individual points.\n","\n","        Args:\n","            point_clouds: List of lists containing point cloud arrays. Each inner list\n","                         represents a frame, and each array contains 3D points (Nx3).\n","            point_cloud_names: Optional names for each point cloud. If not provided,\n","                              names will be automatically generated as \"point_cloud_0\", etc.\n","            point_cloud_colors: Optional colors for each point cloud. Can be uniform colors\n","                               or per-point colors. If not provided, colors will be\n","                               automatically generated using a rainbow colormap.\n","            point_cloud_opacity: Optional list of opacity values for specific point clouds.\n","                                 Each value should be between 0.0 (fully transparent) and 1.0 (fully opaque).\n","                                 If provided, must have the same length as the number of point\n","                                 clouds per frame. If not provided, all point clouds will be\n","                                 fully opaque (opacity=1.0) by default.\n","            point_size: Radius of the spheres used to render each point. Default is 0.01.\n","            point_labels: Optional text labels for individual points. Must match the\n","                         structure of point_clouds (list of lists of strings).\n","            point_label_opacity: Optional list of opacity values for specific point cloud labels.\n","                                 Each value should be between 0.0 (fully transparent) and 1.0 (fully opaque).\n","                                 If provided, must have the same length as the number of point\n","                                 clouds per frame. If not provided, all point labels will be\n","                                 fully opaque (opacity=1.0) by default. Note: The effective opacity\n","                                 of labels will be the minimum of the label opacity and the corresponding\n","                                 point cloud opacity.\n","            label_color: Color for text labels. Default is black.\n","            label_offset: Offset distance for labels from point positions. Default is 0.01.\n","            label_size_in_pixel: Font size for labels in pixels. Default is 20.\n","\n","        Raises:\n","            ValueError: If point_clouds are not in the correct list of lists format,\n","                       or if point_labels don't match the point cloud structure.\n","\n","        Note:\n","            - All frames must contain the same number of point clouds\n","            - Point labels, if provided, must match the number of points in each cloud\n","            - Automatically updates the scene bounding box\n","            - Individual point cloud visibility can be controlled via the hide_point_clouds parameter\n","            - Individual point label visibility can be controlled via the hide_point_labels parameter\n","        \"\"\"\n","        self.point_clouds, self.num_point_clouds_per_frame = (\n","            self._validate_input_is_list_of_lists(point_clouds, \"Point clouds\")\n","        )\n","        self.point_cloud_opacity = (\n","            point_cloud_opacity\n","            if point_cloud_opacity is not None\n","            else [1.0] * self.num_point_clouds_per_frame\n","        )\n","        self.point_size = point_size\n","\n","        self.point_cloud_names = (\n","            point_cloud_names\n","            if point_cloud_names is not None\n","            else [f\"point_cloud_{i}\" for i in range(self.num_point_clouds_per_frame)]\n","        )\n","\n","        # Generate evenly spaced values from 0 to 0.8 for rainbow_r colormap, so that 0 -> red, 0.85 -> blue.\n","        color_indices = np.linspace(0, 0.85, self.num_point_clouds_per_frame)\n","        rainbow_cmap = plt.cm.rainbow_r\n","        # We keep only the RGB values and discard the alpha channel\n","        self.point_cloud_colors = rainbow_cmap(color_indices)[:, :3]\n","        if point_cloud_colors is not None:\n","            # Sample self.num_point_clouds_per_frame colors according to the rainbow color map in matplotlib.\n","            _validate_mesh_colors(point_cloud_colors, self.num_point_clouds_per_frame)\n","            self.point_cloud_colors = _normalize_mesh_colors(\n","                point_cloud_colors, self.point_cloud_colors\n","            )\n","\n","        # Get the bounding box for the added point clouds.\n","        max_point_cloud_corner = -np.inf * np.ones(3)\n","        min_point_cloud_corner = np.inf * np.ones(3)\n","        for one_frame_point_clouds in self.point_clouds:\n","            for point_cloud in one_frame_point_clouds:\n","                max_point_cloud_corner = np.maximum(\n","                    max_point_cloud_corner, np.max(point_cloud, axis=0)\n","                )\n","                min_point_cloud_corner = np.minimum(\n","                    min_point_cloud_corner, np.min(point_cloud, axis=0)\n","                )\n","\n","        # Update the scene bounding box according to the bounding box of all the added point clouds.\n","        self.scene_bbox[0] = np.maximum(self.scene_bbox[0], max_point_cloud_corner)\n","        self.scene_bbox[1] = np.minimum(self.scene_bbox[1], min_point_cloud_corner)\n","\n","        if point_labels is not None:\n","            if not isinstance(point_labels[0], list):\n","                raise ValueError(\n","                    \"Point labels must be a list of lists, where each inner list represents a single frame of point labels.\"\n","                )\n","            self.point_labels = point_labels\n","            for i_point_cloud, point_label in enumerate(self.point_labels):\n","                if not self.point_clouds[0][i_point_cloud].shape[0] == len(point_label):\n","                    raise ValueError(\n","                        \"List of point labels should match the size of each point cloud in one frame.\"\n","                        f\"Got {len(point_label)} point labels for a point cloud with size of f{self.point_clouds[0][i_point_cloud].shape[0]}\"\n","                    )\n","            self.label_color = label_color\n","            self.point_label_offset = label_offset\n","            self.label_size_in_pixel = label_size_in_pixel\n","\n","            # Handle point_label_opacity parameter\n","            self.point_label_opacity = (\n","                point_label_opacity\n","                if point_label_opacity is not None\n","                else [1.0] * self.num_point_clouds_per_frame\n","            )\n","\n","    def add_line_sets(\n","        self,\n","        start_points: list[list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]],\n","        end_points: list[list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]],\n","        line_set_names: list[str] | None = None,\n","        line_set_colors: list[MeshMonoColors | MeshPervertexColors | None]\n","        | None = None,\n","        line_set_opacity: list[float] | None = None,\n","        line_type: str = \"thickline\",  # \"line\", or \"thickline\".\n","        line_start_thickness: float = 0.01,  # Only used when line_type is \"thickline\".\n","    ) -> None:\n","        \"\"\"\n","        Add line sets to the scene for visualization.\n","\n","        Line sets are rendered as lines or thick lines connecting start and end points.\n","        Each line set can have multiple lines defined by start-end points pairs.\n","\n","        Args:\n","            start_points: List of lists containing start point positions. Each inner list\n","                          represents a frame, and each array contains point positions (Nx3).\n","            end_points: List of lists containing end point positions. Must have the same\n","                         structure as start_points. Each start point connects to the\n","                         corresponding end point to form a line.\n","            line_set_names: Optional names for each line set. If not provided, names will be\n","                           automatically generated as \"line_set_0\", \"line_set_1\", etc.\n","            line_set_colors: Optional colors for each line set. If not provided, colors will\n","                            be automatically generated using a rainbow colormap.\n","            line_set_opacity: Optional list of opacity values for specific line sets.\n","                              Each value should be between 0.0 (fully transparent) and 1.0 (fully opaque).\n","                              If provided, must have the same length as the number of line sets\n","                              per frame. If not provided, all line sets will be fully opaque\n","                              (opacity=1.0) by default.\n","            line_type: Type of line rendering. Either \"line\" for simple lines or \"thickline\"\n","                      for variable-thickness lines. Default is \"thickline\".\n","            line_start_thickness: Starting thickness for lines when using \"thickline\" type.\n","                                 Only used when line_type is \"thickline\". Default is 0.01.\n","\n","        Raises:\n","            ValueError: If start_points and end_points don't have matching structures,\n","                       or if line_type is not valid.\n","\n","        Note:\n","            - All frames must contain the same number of line sets\n","            - Start and end points must have matching array shapes within each frame\n","            - Each start point connects to its corresponding end point\n","            - Automatically updates the scene bounding box\n","            - Individual line set visibility can be controlled via the hide_line_sets parameter\n","        \"\"\"\n","        self.start_points, self.end_points, self.num_line_sets_per_frame = (\n","            self._validate_input_pair_are_list_of_lists(\n","                start_points, \"Start points\", end_points, \"End points\"\n","            )\n","        )\n","\n","        self.line_set_opacity = (\n","            line_set_opacity\n","            if line_set_opacity is not None\n","            else [1.0] * self.num_line_sets_per_frame\n","        )\n","\n","        self.line_set_names = (\n","            line_set_names\n","            if line_set_names is not None\n","            else [f\"line_set_{i}\" for i in range(self.num_line_sets_per_frame)]\n","        )\n","\n","        # Generate evenly spaced values from 0 to 0.8 for rainbow_r colormap, so that 0 -> red, 0.85 -> blue.\n","        color_indices = np.linspace(0, 0.85, self.num_line_sets_per_frame)\n","        rainbow_cmap = plt.cm.rainbow_r\n","        # We keep only the RGB values and discard the alpha channel\n","        self.line_set_colors = rainbow_cmap(color_indices)[:, :3]\n","        if line_set_colors is not None:\n","            # Sample self.num_line_sets_per_frame colors according to the rainbow color map in matplotlib.\n","            _validate_mesh_colors(line_set_colors, self.num_line_sets_per_frame)\n","            self.line_set_colors = _normalize_mesh_colors(\n","                line_set_colors, self.line_set_colors\n","            )\n","\n","        # Get the bounding box for the added line sets.\n","        max_line_set_corner = -np.inf * np.ones(3)\n","        min_line_set_corner = np.inf * np.ones(3)\n","        for frame_idx in range(len(self.start_points)):\n","            for line_set_idx in range(self.num_line_sets_per_frame):\n","                line_starts = self.start_points[frame_idx][line_set_idx]\n","                line_ends = self.end_points[frame_idx][line_set_idx]\n","                all_points = np.concatenate([line_starts, line_ends], axis=0)\n","                max_line_set_corner = np.maximum(\n","                    max_line_set_corner, np.max(all_points, axis=0)\n","                )\n","                min_line_set_corner = np.minimum(\n","                    min_line_set_corner, np.min(all_points, axis=0)\n","                )\n","\n","        # Update the scene bounding box according to the bounding box of all the added line sets.\n","        self.scene_bbox[0] = np.maximum(self.scene_bbox[0], max_line_set_corner)\n","        self.scene_bbox[1] = np.minimum(self.scene_bbox[1], min_line_set_corner)\n","\n","        if not line_type.lower() in [\"line\", \"thickline\"]:\n","            raise ValueError(\n","                f\"Invalid line type {line_type}. Must be one of 'line', or 'thickline'.\"\n","            )\n","        self.line_type = line_type.lower()\n","        self.line_start_thickness = line_start_thickness\n","\n","    def add_coordinate_frames(\n","        self,\n","        coordinate_frame_origins: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ],\n","        coordinate_frame_orientations: list[\n","            list[np.ndarray[tuple[int, int], np.dtype[np.float32]]]\n","        ],\n","        coordinate_frame_opacity: list[float] | None = None,\n","        frame_size: float = 0.1,\n","        coordinate_frame_names: list[str] | None = None,\n","    ) -> None:\n","        \"\"\"\n","        Add coordinate frames to the scene for visualization.\n","\n","        Coordinate frames are rendered using ScenePic's built-in coordinate axes visualization,\n","        showing standard RGB-colored axes (X=Red, Y=Green, Z=Blue).\n","\n","        Args:\n","            coordinate_frame_origins: List of lists containing coordinate frame origins.\n","                                    Each inner list represents a frame, and each array\n","                                    contains 3D origin positions (Nx3).\n","            coordinate_frame_orientations: List of lists containing coordinate frame orientations.\n","                                         Must have the same structure as origins. Each array\n","                                         contains 3x3 rotation matrices defining frame orientation.\n","            coordinate_frame_opacity: Optional list of opacity values for specific coordinate frame.\n","                              Each value should be between 0.0 (fully transparent) and 1.0 (fully opaque).\n","                              If provided, must have the same length as the number of coordinate frames\n","                              per frame. If not provided, all coordinate frames will be fully opaque\n","                              (opacity=1.0) by default.\n","            frame_size: Length of each coordinate axis in world units. Default is 0.1.\n","            coordinate_frame_names: Optional names for each coordinate frame. If not provided,\n","                                  names will be automatically generated as \"coordinate_frame_0\", etc.\n","\n","        Raises:\n","            ValueError: If origins and orientations don't have matching structures.\n","\n","        Note:\n","            - All frames must contain the same number of coordinate frames\n","            - Origins and orientations must have matching array shapes within each frame\n","            - Uses ScenePic's native coordinate axes with standard RGB coloring\n","            - Automatically updates the scene bounding box\n","        \"\"\"\n","        (\n","            self.coordinate_frame_origins,\n","            self.coordinate_frame_orientations,\n","            self.num_coordinate_frames_per_frame,\n","        ) = self._validate_input_pair_are_list_of_lists(\n","            coordinate_frame_origins,\n","            \"Coordinate frame origins\",\n","            coordinate_frame_orientations,\n","            \"Coordinate frame orientations\",\n","        )\n","\n","        self.coordinate_frame_names = (\n","            coordinate_frame_names\n","            if coordinate_frame_names is not None\n","            else [\n","                f\"coordinate_frame_{i}\"\n","                for i in range(self.num_coordinate_frames_per_frame)\n","            ]\n","        )\n","\n","        self.coordinate_frame_opacity = (\n","            coordinate_frame_opacity\n","            if coordinate_frame_opacity is not None\n","            else [1.0] * self.num_coordinate_frames_per_frame\n","        )\n","\n","        # Get the bounding box for the added coordinate frames.\n","        max_coordinate_frame_corner = -np.inf * np.ones(3)\n","        min_coordinate_frame_corner = np.inf * np.ones(3)\n","        for frame_idx in range(len(self.coordinate_frame_origins)):\n","            for coordinate_frame_idx in range(self.num_coordinate_frames_per_frame):\n","                origin = self.coordinate_frame_origins[frame_idx][coordinate_frame_idx]\n","                # Consider the extent of the coordinate frame axes based on frame_size\n","                max_coordinate_frame_corner = np.maximum(\n","                    max_coordinate_frame_corner, np.max(origin + frame_size, axis=0)\n","                )\n","                min_coordinate_frame_corner = np.minimum(\n","                    min_coordinate_frame_corner, np.min(origin - frame_size, axis=0)\n","                )\n","\n","        # Update the scene bounding box according to the bounding box of all the added coordinate frames.\n","        self.scene_bbox[0] = np.maximum(self.scene_bbox[0], max_coordinate_frame_corner)\n","        self.scene_bbox[1] = np.minimum(self.scene_bbox[1], min_coordinate_frame_corner)\n","\n","        self.frame_size = frame_size\n","\n","    def set_shading(\n","        self,\n","        background_color: MeshMonoColors | None = None,\n","        ambient_light_color: MeshMonoColors | None = None,\n","        directional_light_color: MeshMonoColors | None = None,\n","        directional_light_dir: np.ndarray[tuple[int], np.dtype[np.float32]]\n","        | None = None,\n","    ) -> None:\n","        \"\"\"\n","        Configure the lighting and shading properties of the scene.\n","\n","        Sets up the background color, ambient lighting, and directional lighting\n","        for the 3D scene. These properties affect how all objects in the scene\n","        are illuminated and rendered.\n","\n","        Args:\n","            background_color: RGB color for the scene background. Default is black [0,0,0].\n","                            Can be specified as float32 values in range [0.0, 1.0] or\n","                            uint8 values in range [0, 255].\n","            ambient_light_color: RGB color for ambient lighting that illuminates all\n","                               objects uniformly. Default is light gray [0.7, 0.7, 0.7].\n","            directional_light_color: RGB color for directional lighting that creates\n","                                   shadows and highlights. Default is dark gray [0.3, 0.3, 0.3].\n","            directional_light_dir: Direction vector for the directional light source.\n","                                 Default is [2, 1, 2], pointing diagonally down and forward.\n","\n","        Note:\n","            - Colors will be automatically normalized to the appropriate format\n","            - The lighting setup affects all objects in the scene\n","            - Changes take effect when the scene is next rendered\n","        \"\"\"\n","        self.shading = sp.Shading(\n","            bg_color=_normalize_mesh_colors([background_color], [_WHITE])[0],\n","            ambient_light_color=_normalize_mesh_colors(\n","                [ambient_light_color], [_LIGHT_GRAY]\n","            )[0],\n","            directional_light_color=_normalize_mesh_colors(\n","                [directional_light_color], [_DARK_GRAY]\n","            )[0],\n","            directional_light_dir=directional_light_dir\n","            if directional_light_dir is not None\n","            else np.array([2, 1, 2]),\n","        )\n","\n","    def show(self, view_height: int = 600, view_width: int = 600) -> None:\n","        \"\"\"\n","        Display the 3D scene in the current Jupyter notebook cell.\n","\n","        Renders the scene with all added assets (meshes, point clouds, line sets,\n","        coordinate frames) and displays it as an interactive HTML widget that can\n","        be manipulated with mouse controls.\n","\n","        Args:\n","            view_height: Height of the rendered view in pixels. Default is 600.\n","            view_width: Width of the rendered view in pixels. Default is 600.\n","\n","        Note:\n","            - This method only works in Jupyter notebook environments\n","            - The rendered scene supports mouse navigation (rotation, zoom, pan)\n","            - If multiple frames are present, the scene will include timeline controls\n","            - The camera will be automatically positioned unless manually set\n","        \"\"\"\n","        self._prepare_rendering(width=view_width, height=view_height)\n","        html_string = self._generate_html_string()\n","        html_object = IPython.display.HTML(html_string)\n","        IPython.display.display(html_object)\n","\n","    def set_camera(\n","        self,\n","        camera_location: np.ndarray[tuple[int], np.dtype[np.float32]],\n","        camera_look_at: np.ndarray[tuple[int], np.dtype[np.float32]],\n","        fov_degrees: float,\n","    ) -> None:\n","        \"\"\"\n","        Manually set the camera position and orientation for the scene.\n","\n","        This overrides the automatic camera positioning based on scene bounding box.\n","        The camera will be fixed at the specified location and orientation for all frames.\n","\n","        Args:\n","            camera_location: The 3D position of the camera in world coordinates.\n","            camera_look_at: The 3D point the camera should focus on in world coordinates.\n","            fov_degrees: The vertical field of view angle in degrees. Controls zoom level.\n","\n","        Note:\n","            - Once manually set, the camera position won't be updated automatically\n","            - A small offset (1e-8) is added to prevent numerical issues when\n","              camera location and look-at point align with coordinate axes\n","            - Aspect ratio is automatically set to 1.0 for square viewports\n","        \"\"\"\n","        self.camera = sp.Camera(\n","            center=camera_location,\n","            look_at=camera_look_at\n","            + 1e-8,  # Added 1e-8 to avoid nan when center and look_at align with coordinate axis.\n","            fov_y_degrees=fov_degrees,\n","            aspect_ratio=1.0,\n","            far_crop_distance=20.0,\n","            near_crop_distance=0.01,\n","        )\n","        self.camera_is_manually_set = True\n","\n","    def render_to_html_string(\n","        self, view_height: int = 600, view_width: int = 600\n","    ) -> str:\n","        \"\"\"\n","        Generate an HTML string representing the 3D scene.\n","\n","        Renders the scene with all added assets (meshes, point clouds, line sets,\n","        coordinate frames) and returns the generated HTML string. This can be used\n","        to embed the scene in other HTML documents or to save it to a file.\n","\n","        Args:\n","            view_height: Height of the rendered view in pixels. Default is 600.\n","            view_width: Width of the rendered view in pixels. Default is 600.\n","\n","        Returns:\n","            str: The generated HTML string representing the 3D scene.\n","        \"\"\"\n","        self._prepare_rendering(width=view_width, height=view_height)\n","        return self._generate_html_string()\n","\n","    def render_to_html_string2(\n","        self, view_height: int = 600, view_width: int = 600\n","    ) -> str:\n","        \"\"\"\n","        Generate an HTML string representing the 3D scene.\n","\n","        Renders the scene with all added assets (meshes, point clouds, line sets,\n","        coordinate frames) and returns the generated HTML string. This can be used\n","        to embed the scene in other HTML documents or to save it to a file.\n","\n","        Args:\n","            view_height: Height of the rendered view in pixels. Default is 600.\n","            view_width: Width of the rendered view in pixels. Default is 600.\n","\n","        Returns:\n","            str: The generated HTML string representing the 3D scene.\n","        \"\"\"\n","        self._prepare_rendering(width=view_width, height=view_height)\n","        return self._generate_html_string2()\n","\n","    def save_to_html(\n","        self, html_file_path: str, view_height: int = 600, view_width: int = 600\n","    ) -> None:\n","        \"\"\"\n","        Save the 3D scene as a standalone HTML file.\n","\n","        Creates a complete HTML document containing the ScenePic visualization and\n","        saves it to the specified file path. The HTML file is self-contained and\n","        can be opened in any modern web browser.\n","\n","        Args:\n","            html_file_path: Path where the HTML file should be saved. Should have\n","                           a .html extension.\n","            view_height: Height of the rendered view in pixels. Default is 600.\n","            view_width: Width of the rendered view in pixels. Default is 600.\n","\n","        Note:\n","            - The generated HTML file is completely standalone\n","            - No external dependencies or internet connection required\n","            - Compatible with modern web browsers supporting WebGL\n","            - Includes mouse navigation controls (rotation, zoom, pan)\n","            - Timeline controls are included if multiple frames are present\n","        \"\"\"\n","        self._prepare_rendering(width=view_width, height=view_height)\n","        html_string = self._generate_html_string()\n","        with open(html_file_path, \"w\") as f:\n","            f.write(html_string)\n","\n","    def _validate_input_is_list_of_lists(\n","        self,\n","        input_data: list[Any],\n","        data_type: str,\n","    ) -> tuple[list[Any], int]:\n","        \"\"\"\n","        Validate the input data is in list of lists format.\n","\n","        Args:\n","            input_data: The input data to validate\n","            data_type: Description of the data type for error messages\n","\n","        Returns:\n","            tuple: (normalized_data, items_per_frame)\n","\n","        Raises:\n","            ValueError: If validation fails\n","        \"\"\"\n","        # Check if input is already list of lists format\n","        for frame_data in input_data:\n","            if not isinstance(frame_data, list):\n","                raise ValueError(\n","                    f\"{data_type} must be a list of lists, where each inner list represents a frame of {data_type.lower()}.\"\n","                )\n","        return input_data, len(input_data[0])\n","\n","    def _setup_mesh_texture_and_vertex_color(\n","        self,\n","        mesh_colors: list[MeshMonoColors | MeshPervertexColors | None] | None = None,\n","        mesh_vertex_uvs: list[np.ndarray[tuple[int, int], np.dtype[np.float32]] | None]\n","        | None = None,\n","        mesh_texture_images: list[\n","            np.ndarray[tuple[int, int, int], np.dtype[np.uint8]] | None\n","        ]\n","        | None = None,\n","    ) -> None:\n","        \"\"\"\n","        Set up mesh texture and vertex colors for rendering.\n","\n","        Args:\n","            mesh_colors: Optional colors for each mesh. Can be per-mesh uniform colors,\n","                        per-vertex colors, or None for individual meshes in mixed rendering.\n","            mesh_vertex_uvs: Optional UV coordinate arrays for per-vertex texture mapping.\n","                            Individual elements can be None for non-textured meshes.\n","            mesh_texture_images: Optional texture image arrays. Individual elements\n","                                can be None for non-textured meshes.\n","\n","        Raises:\n","            ValueError: If validation fails\n","        \"\"\"\n","        # Validate and take mesh vertex colors. Generate mesh vertex colors if not provided.\n","        # Mesh vertex colors are not used if texture images are provided.\n","        # Generate default colors for all meshes\n","        color_indices = np.linspace(0, 0.85, self.num_meshes_per_frame)\n","        rainbow_cmap = plt.cm.rainbow_r\n","        self.mesh_colors = rainbow_cmap(color_indices)[:, :3]\n","        if mesh_colors is not None:\n","            # Standard color validation for non-mixed rendering\n","            _validate_mesh_colors(mesh_colors, self.num_meshes_per_frame)\n","            self.mesh_colors = _normalize_mesh_colors(mesh_colors, self.mesh_colors)\n","\n","        # If texture images are provided, validate UV coordinates and texture images.\n","        if mesh_texture_images is not None:\n","            if (\n","                mesh_vertex_uvs is None\n","            ):  # When texture images are provided, UV coordinates must also be provided.\n","                raise ValueError(\n","                    \"When texture images are provided, Pervertex UV coordinates must also be provided.\"\n","                )\n","            if len(mesh_vertex_uvs) != len(\n","                mesh_texture_images\n","            ):  # UV coordinates and texture images must match.\n","                raise ValueError(\n","                    \"The length of UV coordinates and texture images must match.\"\n","                )\n","            if (\n","                len(mesh_vertex_uvs) != self.num_meshes_per_frame\n","            ):  # UV coordinates and meshes must match.\n","                raise ValueError(\n","                    \"The length of UV coordinates and meshes must match the length of meshes.\"\n","                )\n","            for i, (uv, tex) in enumerate(zip(mesh_vertex_uvs, mesh_texture_images)):\n","                if (uv is None) ^ (\n","                    tex is None\n","                ):  # UV coordinates and texture images must be paired.\n","                    raise ValueError(\n","                        \"UV coordinates and texture images must be paired. The corresponding elements should both or neither be None.\"\n","                    )\n","                elif (\n","                    uv is not None and tex is not None\n","                ):  # When UV coordinates are provided, it must be per-vertex UV, i.e. with a shape of (V x 2).\n","                    if (\n","                        uv.shape[0] != self.meshes[0][i].vertices.shape[0]\n","                        or uv.shape[1] != 2\n","                    ):\n","                        raise ValueError(\n","                            \"UV coordinates must be 2D and have the same length as the number of vertices in the corresponding mesh.\"\n","                        )\n","                    # Assert the tex image is in RGB format with shape (H, W, 3) and uint8 values [0, 255].\n","                    if (\n","                        len(tex.shape) != 3\n","                        or tex.shape[2] != 3\n","                        or tex.dtype != np.uint8\n","                    ):\n","                        raise ValueError(\n","                            \"Texture image must be in RGB format with shape (H, W, 3) and uint8 values [0, 255].\"\n","                        )\n","            self.mesh_vertex_uvs = mesh_vertex_uvs\n","            self.mesh_texture_images = mesh_texture_images\n","\n","    def _validate_input_pair_are_list_of_lists(\n","        self,\n","        input_data: list[Any],\n","        data_type: str,\n","        paired_data: list[Any],\n","        paired_data_type: str,\n","    ) -> tuple[list[Any], list[Any], int]:\n","        \"\"\"\n","        Validate the input data pairs are in list of lists format and the sizes match.\n","\n","        Args:\n","            input_data: The input data to validate\n","            data_type: Description of the data type for error messages\n","            paired_data: The paired data to validate\n","            paired_data_type: Description of the paired data type for error messages\n","\n","        Returns:\n","            tuple: (normalized_data, items_per_frame)\n","\n","        Raises:\n","            ValueError: If validation fails\n","        \"\"\"\n","        for frame_idx, paired_frame_data in enumerate(paired_data):\n","            # Validate paired data is list of lists format.\n","            if not isinstance(paired_frame_data, list):\n","                raise ValueError(\n","                    f\"{paired_data_type} must be a list of lists, where each inner list represents a frame of {paired_data_type.lower()}.\"\n","                )\n","            # Validate paired data and input data have the same number of items per frame.\n","            if len(paired_frame_data) != len(input_data[frame_idx]):\n","                raise ValueError(\n","                    f\"{data_type} and {paired_data_type} must have the same number of items per frame. \"\n","                    f\"In frame {frame_idx}: got {len(paired_frame_data)} {paired_data_type.lower()} \"\n","                    f\"and {len(input_data[frame_idx])} {data_type.lower()}.\"\n","                )\n","\n","        # Validate frame count consistency.\n","        if len(input_data) != len(paired_data):\n","            raise ValueError(\n","                f\"{data_type} and {paired_data_type} must have the same number of frames. \"\n","                f\"Got {len(input_data)} {data_type.lower()} frames and {len(paired_data)} {paired_data_type.lower() if paired_data_type else 'unknown'} frames.\"\n","            )\n","\n","        return input_data, paired_data, len(input_data[0])\n","\n","    def _prepare_rendering(self, height: int = 800, width: int = 800) -> None:\n","        \"\"\"\n","        Prepare the ScenePic scene for rendering.\n","\n","        Sets up the 3D canvas, camera positioning, and all scene assets for rendering.\n","        This is called internally before displaying or saving the scene.\n","\n","        Args:\n","            height: Height of the rendered canvas in pixels. Default is 800.\n","            width: Width of the rendered canvas in pixels. Default is 800.\n","        \"\"\"\n","        canvas3d = self.scene.create_canvas_3d(\n","            height=height, width=width, shading=self.shading\n","        )\n","\n","        self._setup_camera_if_needed()\n","        layer_settings = self._create_layer_settings()\n","        canvas3d.set_layer_settings(layer_settings)\n","\n","        num_frames = self._setup_scene_assets()\n","        self._create_animation_frames(canvas3d, num_frames)\n","\n","    def _setup_camera_if_needed(self) -> None:\n","        \"\"\"Set up automatic camera positioning if not manually configured.\"\"\"\n","        if not self.camera_is_manually_set:\n","            scene_center = (self.scene_bbox[0] + self.scene_bbox[1]) / 2.0\n","            scene_scale = np.max(np.abs(self.scene_bbox[1] - self.scene_bbox[0]))\n","            self.camera = sp.Camera(\n","                center=scene_center + np.array([0.0, 0.0, 2 * scene_scale]),\n","                look_at=scene_center + 1e-8,  # Avoid numerical issues\n","                fov_y_degrees=30.0,\n","                aspect_ratio=1.0,\n","                far_crop_distance=20.0,\n","                near_crop_distance=0.01,\n","            )\n","\n","    def _create_layer_settings(self) -> dict[str, dict[str, Any]]:\n","        \"\"\"Create layer settings for asset opacity control.\"\"\"\n","        layer_settings: dict[str, dict[str, Any]] = {}\n","\n","        # Configure mesh layer settings\n","        if self.mesh_names:\n","            for i, mesh_name in enumerate(self.mesh_names):\n","                opacity = self.mesh_opacity[i]\n","                layer_settings[mesh_name] = {\n","                    \"filled\": False if opacity == 0 else True,\n","                    \"wireframe\": False,\n","                    \"opacity\": 1.0 if opacity == 0 else opacity,\n","                }\n","\n","        # Configure point cloud layer settings\n","        if self.point_cloud_names:\n","            for i, pc_name in enumerate(self.point_cloud_names):\n","                opacity = self.point_cloud_opacity[i]\n","                layer_settings[pc_name] = {\n","                    \"filled\": False if opacity == 0 else True,\n","                    \"wireframe\": False,\n","                    \"opacity\": 1.0 if opacity == 0 else opacity,\n","                }\n","                if self.point_labels:\n","                    # Point label opacity is the minimum of label opacity and point cloud opacity\n","                    effective_label_opacity = min(\n","                        self.point_label_opacity[i], self.point_cloud_opacity[i]\n","                    )\n","                    layer_settings[f\"Labels_{pc_name}\"] = {\n","                        \"filled\": False if effective_label_opacity == 0 else True,\n","                        \"wireframe\": False,\n","                        \"opacity\": 1.0\n","                        if effective_label_opacity == 0\n","                        else effective_label_opacity,\n","                    }\n","\n","        # Configure line set layer settings\n","        if self.line_set_names:\n","            for i, line_name in enumerate(self.line_set_names):\n","                opacity = self.line_set_opacity[i]\n","                layer_settings[line_name] = {\n","                    \"filled\": False if opacity == 0 else True,\n","                    \"wireframe\": False,\n","                    \"opacity\": 1.0 if opacity == 0 else opacity,\n","                }\n","\n","        # Configure coordinate frame layer settings\n","        if self.coordinate_frame_names:\n","            for i, frame_name in enumerate(self.coordinate_frame_names):\n","                opacity = self.coordinate_frame_opacity[i]\n","                layer_settings[frame_name] = {\n","                    \"filled\": False if opacity == 0 else True,\n","                    \"wireframe\": False,\n","                    \"opacity\": 1.0 if opacity == 0 else opacity,\n","                }\n","\n","        return layer_settings\n","\n","    def _setup_scene_assets(self) -> int:\n","        \"\"\"Set up all scene assets and return the number of animation frames.\"\"\"\n","        num_frames = 0\n","\n","        if self.mesh_names:\n","            num_frames = self._add_meshes_to_scene()\n","\n","        if self.point_cloud_names:\n","            num_frames = self._add_point_clouds_to_scene(num_frames)\n","\n","        if self.line_set_names:\n","            num_frames = self._add_line_sets_to_scene(num_frames)\n","\n","        return num_frames\n","\n","    def _create_animation_frames(self, canvas3d: sp.Canvas3D, num_frames: int) -> None:\n","        \"\"\"Create all animation frames with their respective assets.\"\"\"\n","        scene_center = (self.scene_bbox[0] + self.scene_bbox[1]) / 2.0\n","        for frame_index in range(num_frames):\n","            frame = canvas3d.create_frame(\n","                frame_id=f\"{frame_index}\",\n","                camera=self.camera,\n","                # We put the focus_point at the scene_center so that when dragging the mouse\n","                # on the visualization, the scene rotates around its center rather than\n","                # around the camera center. This gives better experience when examine the 3D\n","                # objects.\n","                focus_point=sp.FocusPoint(scene_center, np.zeros(3)),\n","            )\n","\n","            self._add_frame_assets(frame, frame_index)\n","\n","    def _add_frame_assets(self, frame: sp.Frame3D, frame_index: int) -> None:\n","        \"\"\"Add all assets to a specific animation frame.\"\"\"\n","        if self.mesh_names:\n","            self._update_meshes_in_frame(frame, frame_index)\n","\n","        if self.point_cloud_names:\n","            self._update_point_clouds_in_frame(frame, frame_index)\n","        # The scene.update_** methods reduce the size of the scene compared to scene.create_** methods.\n","        # But updating lines and coordinate frames seem not to be supported by scenepic.\n","        if self.line_set_names:\n","            self._add_line_sets_to_frame(frame, frame_index)\n","\n","        if self.coordinate_frame_names:\n","            self._add_coordinate_frames_to_frame(frame, frame_index)\n","\n","    def _update_meshes_in_frame(self, frame: sp.Frame3D, frame_index: int) -> None:\n","        \"\"\"Update meshes in a specific frame.\"\"\"\n","        updated_meshes = []\n","        frame_meshes = self.meshes[frame_index]\n","        for mesh_index, mesh in enumerate(frame_meshes):\n","            updated_meshes.append(\n","                self.scene.update_mesh_positions(\n","                    self.mesh_names[mesh_index], mesh.vertices\n","                )\n","            )\n","        frame.add_meshes(updated_meshes)\n","\n","    def _update_point_clouds_in_frame(\n","        self, frame: sp.Frame3D, frame_index: int\n","    ) -> None:\n","        \"\"\"Update point clouds and labels to a specific frame.\"\"\"\n","        updated_point_clouds = []\n","        labels = []\n","        label_positions = []\n","\n","        frame_point_clouds = self.point_clouds[frame_index]\n","        for pc_index, point_cloud in enumerate(frame_point_clouds):\n","            updated_point_clouds.append(\n","                self.scene.update_instanced_mesh(\n","                    self.point_cloud_names[pc_index], point_cloud\n","                )\n","            )\n","\n","            if self.point_labels:\n","                self._create_point_labels(labels, pc_index, point_cloud)\n","                label_positions.append(point_cloud)\n","\n","        frame.add_meshes(updated_point_clouds)\n","\n","        if self.point_labels and labels:\n","            self._add_labels_to_frame(frame, labels, label_positions)\n","\n","    def _create_point_labels(\n","        self,\n","        labels: list[sp.Label],\n","        pc_index: int,\n","        point_cloud: np.ndarray[tuple[int, int], np.dtype[np.float32]],\n","    ) -> None:\n","        \"\"\"Create labels for points in a point cloud.\"\"\"\n","        for point_id in range(point_cloud.shape[0]):\n","            label = self.scene.create_label(\n","                text=self.point_labels[pc_index][point_id],\n","                color=self.label_color,\n","                layer_id=f\"Labels_{self.point_cloud_names[pc_index]}\",\n","                size_in_pixels=self.label_size_in_pixel,\n","                offset_distance=0.0,\n","            )\n","            labels.append(label)\n","\n","    def _add_labels_to_frame(\n","        self,\n","        frame: sp.Frame3D,\n","        labels: list[sp.Label],\n","        label_positions: list[np.ndarray[tuple[int, int], np.dtype[np.float32]]],\n","    ) -> None:\n","        \"\"\"Add all labels to a frame at their respective positions.\"\"\"\n","        all_positions = np.vstack(label_positions)\n","        for label, position in zip(labels, all_positions):\n","            frame.add_label(\n","                label=label,\n","                position=position + self.point_label_offset,\n","            )\n","\n","    def _add_line_sets_to_frame(self, frame: sp.Frame3D, frame_index: int) -> None:\n","        \"\"\"Add line sets to a specific frame.\"\"\"\n","        updated_line_sets = []\n","        frame_start_points = self.start_points[frame_index]\n","        frame_end_points = self.end_points[frame_index]\n","\n","        for line_set_index in range(self.num_line_sets_per_frame):\n","            start_points = frame_start_points[line_set_index]\n","            end_points = frame_end_points[line_set_index]\n","            line_set_mesh = self.scene.create_mesh(\n","                mesh_id=self.line_set_names[line_set_index],\n","                layer_id=self.line_set_names[line_set_index],\n","            )\n","\n","            self._add_lines_to_mesh(\n","                line_set_mesh, start_points, end_points, line_set_index\n","            )\n","            updated_line_sets.append(line_set_mesh)\n","\n","        frame.add_meshes(updated_line_sets)\n","\n","    def _add_lines_to_mesh(\n","        self,\n","        mesh: sp.Mesh,\n","        start_points: np.ndarray[tuple[int, int], np.dtype[np.float32]],\n","        end_points: np.ndarray[tuple[int, int], np.dtype[np.float32]],\n","        line_set_index: int,\n","    ) -> None:\n","        \"\"\"Add lines to a mesh based on line type.\"\"\"\n","        line_set_color = self.line_set_colors[line_set_index]\n","\n","        if self.line_type == \"line\":\n","            mesh.add_lines(\n","                start_points=start_points,\n","                end_points=end_points,\n","                color=line_set_color,\n","            )\n","        elif self.line_type == \"thickline\":\n","            for start_point, end_point in zip(start_points, end_points):\n","                mesh.add_thickline(\n","                    color=line_set_color,\n","                    start_point=start_point,\n","                    end_point=end_point,\n","                    start_thickness=self.line_start_thickness,\n","                    end_thickness=0.001,\n","                )\n","\n","    def _add_coordinate_frames_to_frame(\n","        self, frame: sp.Frame3D, frame_index: int\n","    ) -> None:\n","        \"\"\"Add coordinate frames to a specific frame.\"\"\"\n","        updated_coordinate_frames = []\n","        frame_origins = self.coordinate_frame_origins[frame_index]\n","        frame_orientations = self.coordinate_frame_orientations[frame_index]\n","\n","        for coord_frame_index in range(self.num_coordinate_frames_per_frame):\n","            origins = frame_origins[coord_frame_index]\n","            orientations = frame_orientations[coord_frame_index]\n","            coordinate_frame_mesh = self.scene.create_mesh(\n","                mesh_id=self.coordinate_frame_names[coord_frame_index],\n","                layer_id=self.coordinate_frame_names[coord_frame_index],\n","            )\n","\n","            self._add_coordinate_axes_to_mesh(\n","                coordinate_frame_mesh, origins, orientations\n","            )\n","            updated_coordinate_frames.append(coordinate_frame_mesh)\n","\n","        frame.add_meshes(updated_coordinate_frames)\n","\n","    def _add_coordinate_axes_to_mesh(\n","        self,\n","        mesh: sp.Mesh,\n","        origins: np.ndarray[tuple[int, int], np.dtype[np.float32]],\n","        orientations: np.ndarray[tuple[int, int], np.dtype[np.float32]],\n","    ) -> None:\n","        \"\"\"Add coordinate axes to a mesh using transform matrices.\"\"\"\n","        # Create transform matrices\n","        transform_matrices = np.zeros((orientations.shape[0], 4, 4), dtype=np.float32)\n","        transform_matrices[..., :3, :3] = orientations\n","        transform_matrices[..., :3, 3] = origins\n","        transform_matrices[..., 3, 3] = 1.0\n","\n","        # Add coordinate axes using ScenePic's built-in function\n","        for transform_matrix in transform_matrices:\n","            mesh.add_coordinate_axes(\n","                length=self.frame_size,\n","                thickness=self.frame_size * 0.1,\n","                transform=transform_matrix,\n","            )\n","\n","    def _add_meshes_to_scene(self) -> int:\n","        \"\"\"\n","        Add meshes to the scene and set up their properties.\n","\n","        Supports mixed rendering: some meshes can use textures while others use vertex colors.\n","\n","        Returns:\n","            int: The number of frames\n","        \"\"\"\n","        # Create texture images for meshes that have textures.\n","        texture_ids: list[str | None] = [None for _ in range(self.num_meshes_per_frame)]\n","        # This is to prevent pyre from complaining about \"Undefined attribute [16]:\n","        # Optional type has no attribute `__getitem__`\" if otherwise we use\n","        # enumerate(self.mesh_texture_images) below. Assign to local variable for type narrowing\n","        mesh_texture_images = self.mesh_texture_images\n","        mesh_vertex_uvs = self.mesh_vertex_uvs\n","        if mesh_texture_images is not None:\n","            for mesh_index, texture_image in enumerate(mesh_texture_images):\n","                if texture_image is not None:\n","                    texture_id = f\"texture_{mesh_index}\"\n","                    scene_image = self.scene.create_image(image_id=texture_id)\n","                    scene_image.from_numpy(texture_image)\n","                    texture_ids[mesh_index] = texture_id\n","\n","        # Create scene meshes with per-mesh vertex colors.\n","        scene_meshes = []\n","        for mesh_index, mesh_name in enumerate(self.mesh_names):\n","            if (\n","                self.mesh_texture_images is not None\n","                and self.mesh_texture_images[mesh_index] is not None\n","            ):  # If the mesh has texture, create a mesh with texture\n","                scene_mesh = self.scene.create_mesh(\n","                    mesh_id=mesh_name,\n","                    layer_id=mesh_name,\n","                    texture_id=texture_ids[mesh_index],\n","                )\n","                # Fix: use local mesh_vertex_uvs variable to avoid Optional type error\n","                scene_mesh.add_mesh_without_normals(\n","                    vertices=self.meshes[0][mesh_index].vertices,\n","                    triangles=self.meshes[0][mesh_index].faces,\n","                    uvs=mesh_vertex_uvs[mesh_index]\n","                    if mesh_vertex_uvs is not None\n","                    else None,\n","                )\n","            else:  # Otherwise, create a mesh with vertex colors\n","                scene_mesh = self.scene.create_mesh(\n","                    mesh_id=mesh_name, layer_id=mesh_name\n","                )\n","                per_vertex_color = _repeat_vertex_color(\n","                    self.mesh_colors[mesh_index],\n","                    self.meshes[0][mesh_index].vertices.shape[0],\n","                    mesh_index,\n","                )\n","                scene_mesh.add_mesh_without_normals(\n","                    vertices=self.meshes[0][mesh_index].vertices,\n","                    triangles=self.meshes[0][mesh_index].faces,\n","                    colors=per_vertex_color,\n","                )\n","            scene_meshes.append(scene_mesh)\n","\n","        num_frames = len(self.meshes)\n","        return num_frames\n","\n","    def _add_point_clouds_to_scene(self, num_frames: int) -> int:\n","        \"\"\"\n","        Add point clouds to the scene and set up their properties.\n","\n","        Args:\n","            num_frames: The current number of frames\n","\n","        Returns:\n","            int: The validated number of frames\n","        \"\"\"\n","        scene_point_clouds = [\n","            self.scene.create_mesh(mesh_id=point_cloud_name, layer_id=point_cloud_name)\n","            for point_cloud_name in self.point_cloud_names\n","        ]\n","        if num_frames == 0:\n","            num_frames = len(self.point_clouds)\n","        else:\n","            if num_frames != len(self.point_clouds):\n","                raise ValueError(\n","                    f\"Invalid point clouds. Expected a list of point clouds, where the length matches the number of mesh frames or other 3D input assets. Got {len(self.point_clouds)} point clouds for {num_frames} frames.\"\n","                )\n","        for point_cloud_index, point_cloud in enumerate(self.point_clouds[0]):\n","            per_point_color = _repeat_vertex_color(\n","                self.point_cloud_colors[point_cloud_index],\n","                point_cloud.shape[0],\n","                point_cloud_index,\n","            )\n","            scene_point_clouds[point_cloud_index].add_sphere(\n","                sp.Colors.White, transform=sp.Transforms.Scale(self.point_size)\n","            )\n","            scene_point_clouds[point_cloud_index].enable_instancing(\n","                point_cloud, colors=per_point_color\n","            )\n","        return num_frames\n","\n","    def _add_line_sets_to_scene(self, num_frames: int) -> int:\n","        \"\"\"\n","        Add line sets to the scene and validate the number of frames.\n","\n","        Args:\n","            num_frames: The current number of frames\n","\n","        Returns:\n","            int: The validated number of frames\n","        \"\"\"\n","        if num_frames == 0:\n","            num_frames = len(self.start_points)\n","        else:\n","            if num_frames != len(self.start_points):\n","                raise ValueError(\n","                    f\"Invalid line sets. Expected a list of line sets, where the length matches the number of mesh frames or other 3D input assets. Got {len(self.start_points)} line set frames for {num_frames} frames.\"\n","                )\n","        return num_frames\n","\n","    def _generate_html_string(self) -> str:\n","        \"\"\"\n","        Generate an HTML string containing the complete ScenePic visualization.\n","\n","        Creates a standalone HTML document with embedded JavaScript that contains\n","        the full 3D scene data and ScenePic viewer. The resulting HTML can be\n","        saved to a file or displayed in web browsers.\n","\n","        Returns:\n","            str: Complete HTML document string with embedded ScenePic scene\n","\n","        Note:\n","            - The HTML includes the full ScenePic JavaScript library\n","            - Scene data is embedded directly in the HTML for standalone viewing\n","            - The generated HTML is self-contained and doesn't require external resources\n","            - Compatible with modern web browsers supporting WebGL\n","        \"\"\"\n","        SP_LIB = sp.js_lib_src()\n","        SP_SCRIPT = self.scene.get_script().replace(\n","            \"window.onload = function()\", \"function scenepic_foo()\"\n","        )\n","        HTML_string = (\n","            \"<!DOCTYPE html>\"\n","            '<html lang=\"en\">'\n","            \"<head>\"\n","            '<meta charset=\"utf-8\">'\n","            \"<title>ScenePic </title>\"\n","            f\"<script>{SP_LIB}</script>\"\n","            f\"<script>{SP_SCRIPT} scenepic_foo();</script>\"\n","            \"</head>\"\n","            '<body onload=\"scenepic_foo()\">  </body>'\n","            \"</html>\"\n","        )\n","        return HTML_string\n","\n","    def _generate_html_string2(self) -> str:\n","        \"\"\"\n","        Generate an HTML string containing the complete ScenePic visualization.\n","\n","        Creates a standalone HTML document with embedded JavaScript that contains\n","        the full 3D scene data and ScenePic viewer. The resulting HTML can be\n","        saved to a file or displayed in web browsers.\n","\n","        Returns:\n","            str: Complete HTML document string with embedded ScenePic scene\n","\n","        Note:\n","            - The HTML includes the full ScenePic JavaScript library\n","            - Scene data is embedded directly in the HTML for standalone viewing\n","            - The generated HTML is self-contained and doesn't require external resources\n","            - Compatible with modern web browsers supporting WebGL\n","        \"\"\"\n","        SP_LIB = sp.js_lib_src()\n","        SP_SCRIPT = self.scene.get_script().replace(\n","            \"window.onload = function()\", \"function scenepic_foo()\"\n","        )\n","        HTML_div = (\n","            \"<div id='scene-div'></div>\"\n","            f\"<script>{SP_LIB}</script>\"\n","            f\"<script>{SP_SCRIPT}</script>\"\n","            \"<script>scenepic_foo();</script>\"\n","        )\n","        return HTML_div\n","\n","\n","def _validate_mesh_colors(\n","    colors: list[MeshMonoColors | MeshPervertexColors | None], num_meshes: int\n",") -> None:\n","    \"\"\"\n","    Validate mesh colors configuration.\n","\n","    Args:\n","        colors: The mesh colors array to validate\n","        num_meshes: Expected number of meshes\n","\n","    Raises:\n","        ValueError: If the mesh colors are invalid\n","\n","    Validates:\n","        - Shape is (num_meshes, (v x ) 4)\n","        - Data type is supported (uint8, int32, int64, float32, float64)\n","        - Value ranges are appropriate for the data type\n","    \"\"\"\n","    if len(colors) != num_meshes:\n","        raise ValueError(\n","            f\"Invalid mesh colors. Expected a list of mesh colors, where the length matches the number of meshes. Got {len(colors)} colors for {num_meshes} meshes.\"\n","        )\n","\n","    # Check data type and value ranges\n","    for color in colors:\n","        if color is not None:\n","            if (\n","                color.dtype == np.uint8\n","                or color.dtype == np.int32\n","                or color.dtype == np.int64\n","            ):\n","                # Integer values should be in range [0, 255]\n","                if not np.all((color >= 0) & (color <= 255)):\n","                    raise ValueError(\n","                        \"Invalid mesh colors. Integer color values are expected in range [0, 255].\"\n","                    )\n","            elif color.dtype in [np.float32, np.float64]:\n","                # Float values should be in range [0.0, 1.0]\n","                if not np.all((color >= 0.0) & (color <= 1.0)):\n","                    raise ValueError(\n","                        \"Invalid mesh colors. Float color values are expected in range [0.0, 1.0].\"\n","                    )\n","            else:\n","                raise ValueError(\n","                    \"Invalid mesh colors. Unsupported data type. Expected uint8, int32, int64, float32, or float64.\"\n","                )\n","\n","\n","def _normalize_mesh_colors(\n","    colors: list[MeshPervertexColors | MeshMonoColors | None],\n","    default_colors: list[MeshPervertexColors | MeshMonoColors],\n",") -> list[MeshPervertexColors | MeshMonoColors]:\n","    \"\"\"\n","    Normalize mesh colors to uint8 values in range [0, 255].\n","\n","    Args:\n","        colors: Input mesh colors in any supported format\n","\n","    Returns:\n","        Normalized colors as a list of uint8 array in range [0, 255]\n","    \"\"\"\n","    normalized_colors = []\n","\n","    for i, color in enumerate(colors):\n","        if color is not None:\n","            if color.dtype in [np.uint8, np.int32, np.int64]:\n","                # Convert integer colors to float32 in range [0.0, 1.0]\n","                normalized_colors.append(color.astype(np.float32) / 255.0)\n","            elif color.dtype in [np.float32, np.float64]:\n","                # Already normalized float colors, ensure they are float32\n","                normalized_colors.append(color.astype(np.float32))\n","            else:\n","                raise ValueError(\n","                    \"Invalid mesh colors. Unsupported data type. Expected uint8, int32, int64, float32, or float64.\"\n","                )\n","        else:\n","            normalized_colors.append(default_colors[i])\n","\n","    return normalized_colors\n","\n","\n","def _repeat_vertex_color(\n","    mesh_color: MeshPervertexColors | MeshMonoColors, num_vertices: int, mesh_index: int\n",") -> MeshPervertexColors:\n","    \"\"\"\n","    Repeat mesh color to match the number of vertices if needed.\n","\n","    Args:\n","        mesh_color: The mesh color array\n","        num_vertices: Number of vertices in the mesh\n","        mesh_index: Index of the mesh for error reporting\n","\n","    Returns:\n","        MeshMeshPervertexColors: Color array matching the number of vertices\n","\n","    Raises:\n","        ValueError: If the mesh color format is invalid\n","    \"\"\"\n","    if mesh_color.ndim == 1:\n","        # Single color (3,) -> expand to per-vertex colors (num_vertices, 3)\n","        mesh_color = np.repeat(mesh_color[np.newaxis, ...], num_vertices, axis=0)\n","    elif mesh_color.ndim == 2 and mesh_color.shape[0] == 1:\n","        # Single color (1, 3) -> expand to per-vertex colors (num_vertices, 3)\n","        mesh_color = np.repeat(mesh_color, num_vertices, axis=0)\n","    elif mesh_color.ndim == 2 and mesh_color.shape[0] == num_vertices:\n","        # Already per-vertex colors (num_vertices, 3) -> no change needed\n","        pass\n","    else:\n","        raise ValueError(\n","            f\"Invalid mesh color. The shape for {mesh_index} mesh color has the shape of {mesh_color.shape}, which is neither of the following accepted format: \\n (3) or (1, 3): a uniform color for the whole mesh. \\n (v, 3): per-vertex color for the mesh.\"\n","        )\n","\n","    return mesh_color"],"metadata":{"cellView":"form","id":"Z1kz-LIQIZGQ","executionInfo":{"status":"ok","timestamp":1763524672190,"user_tz":-60,"elapsed":221,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#@title Helper function for interactive posing\n","# Get the influence of each pose parameter to joints.\n","joint_names = scripted_mhr_model.get_joint_names()\n","num_joints = len(joint_names)\n","pose_parameter_names = scripted_mhr_model.get_parameter_names()[:-45]\n","influence_matrix = (\n","    scripted_mhr_model.get_parameter_transform().numpy().astype(bool).T\n",")\n","influence_mapping = {}\n","for pose_parameter_name, joint_mask in zip(pose_parameter_names, influence_matrix):\n","    influence_mapping[pose_parameter_name] = []\n","    influenced_joint_indices = np.nonzero(joint_mask.reshape(num_joints, 7).sum(1))[\n","        0\n","    ].tolist()\n","    for influenced_joint_index in influenced_joint_indices:\n","        influence_mapping[pose_parameter_name].append(\n","            joint_names[influenced_joint_index]\n","        )\n","\n","# Get the pose parameter limits.\n","pose_parameter_limits = scripted_mhr_model.get_parameter_limits()\n","\n","num_pca_comp = scripted_mhr_model.get_num_identity_blendshapes()\n","# Visualize the pose MHR into html string.\n","def visualize_posed_mhr_model(\n","    pose_parameters,\n","    pca_coeffs=np.zeros(\n","        (1, num_pca_comp), dtype=np.float32\n","    ),\n","    face_expr_coeffs=np.zeros(\n","        (1, 72), dtype=np.float32\n","    ),\n","    affected_joints_names=[],\n",") -> str:\n","    params = torch.from_numpy(pose_parameters)\n","    identity_coeffs = torch.from_numpy(pca_coeffs)\n","    face_expr_coeffs = torch.from_numpy(face_expr_coeffs)\n","\n","    # Get body mesh.\n","    body_vertices, skel_state = (\n","        scripted_mhr_model(\n","            identity_coeffs=identity_coeffs,\n","            model_parameters=params,\n","            face_expr_coeffs=face_expr_coeffs,\n","        )\n","    )\n","    body_vertices = body_vertices.numpy()[0] / 100.0\n","    body_faces = scripted_mhr_model.character_torch.mesh.faces.cpu().numpy()\n","    body_mesh = trimesh.Trimesh(body_vertices, body_faces, process=False)\n","\n","    # Get joint locations.\n","    skel_state = skel_state.numpy()[0]\n","    joint_locations = skel_state[..., :3] / 100.0\n","    joint_names = scripted_mhr_model.get_joint_names()\n","\n","    # Get the skeleton structure.\n","    joint_parents = scripted_mhr_model.character_torch.skeleton.joint_parents\n","    joint_parents = np.clip(np.array(joint_parents), 0, np.inf).astype(\n","        np.int32\n","    )  # So that the root points to itself.\n","    parent_joint_locations = joint_locations[joint_parents]\n","\n","    # Get the kinematic joints (If a joint is a parent of another, then it is a kinematic joint).\n","    kinematic_joints = joint_locations[np.unique(joint_parents)]\n","    kinematic_joints_names = [joint_names[i] for i in np.unique(joint_parents)]\n","\n","    # Get joint local coordinate orientations.\n","    joint_orientations = skel_state[..., 3:7]\n","    joint_orientations = R.Rotation.from_quat(joint_orientations).as_matrix()\n","    kinematic_joint_orientations = joint_orientations[np.unique(joint_parents)]\n","\n","    # Get affected joints.\n","    if (\n","        len(affected_joints_names) == 1\n","    ):  # Duplicate the single joint to avoid visualization issue on a single point.\n","        affected_joints_names += affected_joints_names\n","    affected_joints_indices = [\n","        joint_names.index(joint_name) for joint_name in affected_joints_names\n","    ]\n","    if affected_joints_names:\n","        affected_joints_locations = joint_locations[affected_joints_indices]\n","\n","    # Visualize the mean body mesh.\n","    visualizer = ScenepicVisualization()\n","    visualizer.add_meshes(\n","        meshes=[[body_mesh]],\n","        mesh_names=[\"Body surface\"],\n","        mesh_colors=[sp.Colors.Blue],\n","        mesh_opacity=[0.6],\n","    )\n","    # Visualize all the joints (red), kinematic joints (blue), and affected joints (purple).\n","    if affected_joints_names:\n","        visualizer.add_point_clouds(\n","            point_clouds=[\n","                [joint_locations, kinematic_joints, affected_joints_locations]\n","            ],\n","            point_cloud_names=[\"Joints\", \"Kinematic joints\", \"Affected joints\"],\n","            point_cloud_opacity=[0.0, 0.5, 1.0],\n","            point_size=0.02,\n","            point_labels=[joint_names, kinematic_joints_names, affected_joints_names],\n","            point_label_opacity=[0.0, 0.0, 1.0],\n","            label_size_in_pixel=30,\n","            label_offset=0.01,\n","            point_cloud_colors=[sp.Colors.Red, sp.Colors.Blue, sp.Colors.Purple],\n","        )\n","    else:\n","        visualizer.add_point_clouds(\n","            point_clouds=[[joint_locations, kinematic_joints]],\n","            point_cloud_names=[\"Joints\", \"Kinematic joints\"],\n","            point_cloud_opacity=[0.0, 1.0],\n","            point_size=0.02,\n","            point_labels=[joint_names, kinematic_joints_names],\n","            label_size_in_pixel=30,\n","            label_offset=0.01,\n","            point_cloud_colors=[sp.Colors.Red, sp.Colors.Blue],\n","        )\n","\n","    # Visualize the skeleton.\n","    visualizer.add_line_sets(\n","        start_points=[[parent_joint_locations]],\n","        end_points=[[joint_locations]],\n","        line_set_colors=[sp.Colors.Green],\n","        line_set_names=[\"Skeleton\"],\n","        line_start_thickness=0.015,\n","    )\n","    # Visualize joint orientations.\n","    visualizer.add_coordinate_frames(\n","        coordinate_frame_origins=[[joint_locations, kinematic_joints]],\n","        coordinate_frame_orientations=[\n","            [joint_orientations, kinematic_joint_orientations]\n","        ],\n","        coordinate_frame_opacity=[0.0, 0.0],\n","        coordinate_frame_names=[\"Joints local frames\", \"Kinematic joint local frames\"],\n","        frame_size=0.04,\n","    )\n","\n","    visualizer.show()"],"metadata":{"cellView":"form","id":"nWYeWU32rNnq","executionInfo":{"status":"ok","timestamp":1763524672193,"user_tz":-60,"elapsed":1,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#@title Helper function for identity and expression space visualization\n","from functools import reduce\n","\n","def visualize_blendshape_space(\n","    pc_indices: list[int],\n","    model_params,\n","    mesh_faces,\n","    num_frames = 48,\n","    num_pca_comp=45,\n","    face_expr_dim=15,\n","    is_expression=False,\n","    face_mask=None,\n","    ):\n","    num_pc = len(pc_indices)\n","    left_most_frame_idx = num_frames // 4\n","    middle_frame_idx = num_frames // 2\n","    right_most_frame_idx = num_frames // 4 * 3\n","    meshes = [num_pc * [trimesh.Trimesh()] for i in range(num_frames)]\n","    for i_th_pc, pc_idx in enumerate(pc_indices):\n","        identity_coeffs = torch.zeros(1, num_pca_comp)\n","        face_expr_coeffs = torch.zeros(1, face_expr_dim)\n","        start = -3.0\n","        end = 3.0\n","        if is_expression:\n","            start = -2.0\n","            end = 2.0\n","        for i_th_frame, sigma in enumerate(np.linspace(start, end, num_frames // 2 + 1)):\n","            if is_expression:\n","                face_expr_coeffs[0, pc_idx] = sigma\n","            else:\n","                identity_coeffs[0, pc_idx] = sigma\n","            body_vertices, _= scripted_mhr_model(\n","                    identity_coeffs=identity_coeffs,\n","                    model_parameters=model_params,\n","                    face_expr_coeffs=face_expr_coeffs,\n","                )\n","            body_vertices = body_vertices.numpy()[0] / 100.0\n","\n","            mesh = trimesh.Trimesh(body_vertices, mesh_faces, process=False)\n","            if face_mask is not None:\n","                mesh.update_faces(face_mask)\n","                mesh.remove_unreferenced_vertices()\n","                mesh = trimesh.Trimesh(mesh.vertices, mesh.faces, process=False)\n","\n","            meshes[left_most_frame_idx + i_th_frame][i_th_pc] = mesh\n","        for i_th_frame in range(0, left_most_frame_idx):\n","            meshes[i_th_frame][i_th_pc] = meshes[middle_frame_idx - i_th_frame][i_th_pc]\n","        for i_th_frame in range(right_most_frame_idx + 1, num_frames):\n","            meshes[i_th_frame][i_th_pc] = meshes[2 * right_most_frame_idx - i_th_frame][\n","                i_th_pc\n","            ]\n","    return meshes\n","\n","def get_head_hand_mask():\n","    joint_names = scripted_mhr_model.get_joint_names()\n","    sw_index, sw_weight = scripted_mhr_model.get_lbsw()\n","    sw_index = sw_index.numpy()\n","    sw_weight = sw_weight.numpy()\n","    hand_joints = {side:[i for i, n in enumerate(joint_names) if (n.startswith(f'{side}_thumb') or\n","                                                                  n.startswith(f'{side}_index') or\n","                                                                  n.startswith(f'{side}_middle') or\n","                                                                  n.startswith(f'{side}_ring') or\n","                                                                  n.startswith(f'{side}_pinky') or\n","                                                                  n.startswith(f'{side}_wrist'))]\n","                for side in ('l', 'r')}\n","\n","    hand_indices = {side:reduce(np.logical_or, [sw_index == i for i in joints])\n","                for side, joints in hand_joints.items()}\n","    hand_softmasks_orig = {side:np.multiply(hand_index, sw_weight).sum(axis=1)\n","                        for side, hand_index in hand_indices.items()}\n","    right_hand_mask = hand_softmasks_orig['r']\n","\n","    head_or_neck_joints = [i for i, c in enumerate(joint_names) if (c.startswith('c') and not c.startswith('c_spine'))]\n","    head_or_neck_index = reduce(np.logical_or, [sw_index == i for i in head_or_neck_joints])\n","    head_or_neck_softmask = np.multiply(head_or_neck_index, sw_weight).sum(axis=1)\n","\n","    return head_or_neck_softmask, right_hand_mask"],"metadata":{"cellView":"form","id":"e7fwtk8pAfDF","executionInfo":{"status":"ok","timestamp":1763524672207,"user_tz":-60,"elapsed":14,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["# MHR Visualizations"],"metadata":{"id":"zERA4lNbfLft"}},{"cell_type":"code","source":["#@title 1. Visualize the model rig.\n","\n","import scipy.spatial.transform as R\n","\n","# Initialize the model parameters: global rotation, translation, joint angles, and blendshape coefficients.\n","rot = torch.zeros(1, 3)  # Global Rotation\n","trans = torch.zeros(1, 3)  # Translation\n","lbs_model_parms = torch.zeros(1, 198)  # Joint angles and scalings, feel free to change the values here to pose the model.\n","params = torch.hstack((trans, rot, lbs_model_parms))\n","\n","num_pca_comp = scripted_mhr_model.get_num_identity_blendshapes()\n","identity_coeffs = torch.zeros(1, num_pca_comp)\n","face_expr_coeffs = torch.zeros(1, 72)\n","\n","# Get the mean model mesh.\n","mean_model_vertices, skel_state = (\n","    scripted_mhr_model(\n","        model_parameters=params,\n","        identity_coeffs=identity_coeffs,\n","        face_expr_coeffs=face_expr_coeffs,\n","    )\n",")\n","\n","mean_model_vertices = mean_model_vertices.numpy()[0] / 100.0\n","faces = scripted_mhr_model.character_torch.mesh.faces.cpu().numpy()\n","mean_model_mesh = trimesh.Trimesh(mean_model_vertices, faces, process=False)\n","\n","# Get the joint locations.\n","skel_state = skel_state.numpy()[0]\n","joint_locations = skel_state[..., :3] / 100.0\n","joint_names = scripted_mhr_model.get_joint_names()\n","\n","# Get the skeleton structure.\n","joint_parents = scripted_mhr_model.character_torch.skeleton.joint_parents\n","joint_parents = np.clip(np.array(joint_parents), 0, np.inf).astype(\n","    np.int32\n",")  # So that the root points to itself.\n","parent_joint_locations = joint_locations[joint_parents]\n","\n","# Get the kinematic joints (If a joint is a parent of another, then it is a kinematic joint).\n","kinematic_joints = joint_locations[np.unique(joint_parents)]\n","kinematic_joints_names = [joint_names[i] for i in np.unique(joint_parents)]\n","\n","# Get joint local coordinate orientations.\n","joint_orientations = skel_state[..., 3:7]\n","joint_orientations = R.Rotation.from_quat(joint_orientations).as_matrix()\n","kinematic_joint_orientations = joint_orientations[np.unique(joint_parents)]\n","\n","# Visualize the mean body mesh.\n","visualizer = ScenepicVisualization()\n","visualizer.add_meshes(\n","    meshes=[[mean_model_mesh]],\n","    mesh_names=[\"Template body surface\"],\n","    mesh_opacity=[0.9],\n","    mesh_colors=[sp.Colors.Blue],\n",")\n","# Visualize all the joints (red) and kinematic joints (blue).\n","visualizer.add_point_clouds(\n","    point_clouds=[[joint_locations, kinematic_joints]],\n","    point_cloud_names=[\"Joints\", \"Kinematic joints\"],\n","    point_cloud_opacity=[0.0, 1.0],\n","    point_size=0.02,\n","    point_labels=[joint_names, kinematic_joints_names],\n","    point_label_opacity=[0.0, 0.0],\n","    label_size_in_pixel=30,\n","    label_offset=0.01,\n","    point_cloud_colors=[sp.Colors.Red, sp.Colors.Blue],\n",")\n","# Visualize the skeleton.\n","visualizer.add_line_sets(\n","    start_points=[[parent_joint_locations]],\n","    end_points=[[joint_locations]],\n","    line_set_colors=[sp.Colors.Green],\n","    line_set_names=[\"Skeleton\"],\n","    line_start_thickness=0.015,\n",")\n","# Visualize joint orientations.\n","visualizer.add_coordinate_frames(\n","    coordinate_frame_origins=[[joint_locations, kinematic_joints]],\n","    coordinate_frame_orientations=[[joint_orientations, kinematic_joint_orientations]],\n","    coordinate_frame_names=[\"Joints local frames\", \"Kinematic joint local frames\"],\n","    coordinate_frame_opacity=[0.0, 0.0],\n","    frame_size=0.04,\n",")\n","\n","print(\n","    \"How to use the visualization?\\n\"\n","    \"    Toggle layers and information from the top right drop-down button.\\n\"\n","    \"    Change the opacity/transparency use the bars in the drop-down button.\\n\"\n","    \"    Drag the mouse to rotate the view.\\n\"\n","    \"    Scroll to zoom in/out.\\n\"\n","    \"    Hold the shift key and drag the mouse to move around.\\n\"\n",")\n","visualizer.show()"],"metadata":{"id":"7THwY0CYJhr7","executionInfo":{"status":"ok","timestamp":1763524673702,"user_tz":-60,"elapsed":1493,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"colab":{"base_uri":"https://localhost:8080/","height":878,"output_embedded_package_id":"1o5kh38Sf9olzY9f-v7ZWBkHHscqOmzQe"},"cellView":"form","outputId":"4d34ea31-0d3c-4285-8d38-1cff6a689c3c"},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":[],"metadata":{"id":"J2vVX-Ykc70S"}},{"cell_type":"code","source":["#@title 2. Interactive model deforming.\n","import ipywidgets as widgets\n","import numpy as np\n","import IPython\n","import scenepic as sp\n","import trimesh\n","import scipy.spatial.transform as R\n","\n","parameter_values = {param: 0.0 for param in pose_parameter_names}\n","last_selected_parameter = pose_parameter_names[0]\n","\n","# Create interactive visualization GUI.\n","class BentoParameterInterface:\n","    def __init__(\n","        self,\n","        pose_parameters,\n","        parameter_limits,\n","        parameter_to_kinematic_joints,\n","        render_posed_mhr,\n","    ):\n","        \"\"\"\n","        Initialize the parameter control interface optimized for Bento\n","        \"\"\"\n","        self.pose_parameters = pose_parameters\n","        self.parameter_limits = parameter_limits\n","        self.parameter_to_kinematic_joints = parameter_to_kinematic_joints\n","        self.render_posed_mhr = render_posed_mhr\n","\n","        # Initialize the associated joints\n","        self.associted_joints = []\n","\n","        # Flag to prevent infinite loops during updates\n","        self._updating = False\n","\n","        # Create widgets\n","        self._create_widgets()\n","        self._setup_observers()\n","        self._update_parameter_info()\n","\n","        pose_parm_values = np.array(\n","            [\n","                parameter_values[parameter_name]\n","                for parameter_name in self.pose_parameters\n","            ]\n","        ).astype(np.float32)[np.newaxis, ...]\n","        rendered_html = self.render_posed_mhr(\n","            pose_parm_values, affected_joints_names=self.associted_joints\n","        )\n","\n","\n","    def _create_widgets(self):\n","        \"\"\"Create all the widgets for the interface\"\"\"\n","\n","        # Parameter dropdown\n","        self.parameter_dropdown = widgets.Dropdown(\n","            options=self.pose_parameters,\n","            value=last_selected_parameter,\n","            description=\"Parameter:\",\n","            style={\"description_width\": \"initial\"},\n","            layout=widgets.Layout(width=\"95%\"),\n","        )\n","\n","        # Slider for parameter value\n","        current_param = self.parameter_dropdown.value\n","        current_idx = self.pose_parameters.index(current_param)\n","        min_val, max_val = self.parameter_limits[current_idx]\n","\n","        self.parameter_slider = widgets.FloatSlider(\n","            value=0.0,\n","            min=min_val,\n","            max=max_val,\n","            step=0.01,\n","            description=\"Value:\",\n","            continuous_update=False,\n","            style={\"description_width\": \"initial\"},\n","            layout=widgets.Layout(width=\"95%\"),\n","        )\n","\n","        # Reset buttons\n","        self.reset_current_button = widgets.Button(\n","            description=\"Reset Current Parameter\",\n","            button_style=\"warning\",\n","            layout=widgets.Layout(width=\"48%\"),\n","        )\n","\n","        self.reset_all_button = widgets.Button(\n","            description=\"Reset All\",\n","            button_style=\"danger\",\n","            layout=widgets.Layout(width=\"48%\"),\n","        )\n","\n","        # Button container\n","        self.button_box = widgets.HBox(\n","            [self.reset_current_button, self.reset_all_button],\n","            layout=widgets.Layout(justify_content=\"space-between\"),\n","        )\n","\n","        # Left panel (controls) - 1/4 width\n","        self.left_panel = widgets.VBox(\n","            [self.parameter_dropdown, self.parameter_slider, self.button_box],\n","            layout=widgets.Layout(width=\"40%\", padding=\"10px\", border=\"1px solid #ccc\"),\n","        )\n","\n","        # Middle panel (current parameter info) - 1/4 width\n","        self.middle_panel = widgets.HTML(\n","            value=\"\",\n","            layout=widgets.Layout(\n","                width=\"60%\",\n","                height=\"170px\",\n","                padding=\"20px\",\n","                border=\"0px solid #ccc\",\n","                overflow=\"auto\",\n","            ),\n","        )\n","\n","\n","        # Top container\n","        self.main_container = widgets.HBox(\n","            [self.left_panel, self.middle_panel],\n","            layout=widgets.Layout(width=\"98%\"),\n","        )\n","\n","    def _setup_observers(self):\n","        \"\"\"Setup event observers for widgets\"\"\"\n","        self.parameter_dropdown.observe(self._on_parameter_change, names=\"value\")\n","        self.parameter_slider.observe(self._on_slider_change, names=\"value\")\n","        self.reset_current_button.on_click(self._on_reset_current)\n","        self.reset_all_button.on_click(self._on_reset_all)\n","\n","    def _on_parameter_change(self, change):\n","        \"\"\"Handle parameter dropdown change\"\"\"\n","        if self._updating:\n","            return\n","\n","        self._updating = True\n","        try:\n","            new_param = change[\"new\"]\n","            param_idx = self.pose_parameters.index(new_param)\n","            min_val, max_val = self.parameter_limits[param_idx]\n","\n","            # First update the slider range\n","            self.parameter_slider.min = min_val\n","            self.parameter_slider.max = max_val\n","\n","            # Then set the slider value to the stored value for this parameter\n","            stored_value = parameter_values[new_param]\n","            self.parameter_slider.value = stored_value\n","\n","            # Update displays\n","            self._update_parameter_info()\n","\n","            # Update the associated joints\n","            self.associted_joints = self.parameter_to_kinematic_joints.get(\n","                new_param, []\n","            )\n","            last_selected_parameter = new_param\n","\n","        finally:\n","            print(\"associates joints\", self.associted_joints)\n","            self._updating = False\n","            self._render_result()\n","\n","    def _on_slider_change(self, change):\n","        \"\"\"Handle slider value change\"\"\"\n","        if self._updating:\n","            return\n","\n","        current_param = self.parameter_dropdown.value\n","        new_value = change[\"new\"]\n","\n","        # Update stored value\n","        parameter_values[current_param] = new_value\n","\n","        # Update displays\n","        self._update_parameter_info()\n","\n","        self._render_result()\n","\n","    def _on_reset_current(self, button):\n","        \"\"\"Handle reset current parameter button\"\"\"\n","        self._updating = True\n","        try:\n","            current_param = self.parameter_dropdown.value\n","            parameter_values[current_param] = 0.0\n","            self.parameter_slider.value = 0.0\n","\n","            # Update displays\n","            self._update_parameter_info()\n","        finally:\n","            self._updating = False\n","            self._render_result()\n","\n","    def _on_reset_all(self, button):\n","        \"\"\"Handle reset all button\"\"\"\n","        self._updating = True\n","        try:\n","            # Reset all values to 0\n","            for param in self.pose_parameters:\n","                parameter_values[param] = 0.0\n","\n","            # Reset current slider\n","            self.parameter_slider.value = 0.0\n","\n","            # Update displays\n","            self._update_parameter_info()\n","        finally:\n","            self._updating = False\n","            self._render_result()\n","\n","    def _update_parameter_info(self):\n","        \"\"\"Update the middle panel with current parameter information\"\"\"\n","        current_param = self.parameter_dropdown.value\n","        param_idx = self.pose_parameters.index(current_param)\n","        min_val, max_val = self.parameter_limits[param_idx]\n","        current_value = parameter_values[current_param]\n","\n","        joints = self.parameter_to_kinematic_joints.get(\n","            current_param, [\"No joints associated\"]\n","        )\n","        joints_str = \"<br>\".join([f\"  • {joint}\" for joint in joints])\n","        self.associted_joints = joints\n","\n","        html_content = f\"\"\"\n","        <div style=\"font-family: Arial, sans-serif;\">\n","            <div style=\"display: flex; justify-content: space-between;\">\n","                <div style=\"width: 48%;\">\n","                    <div style=\"margin-bottom: 10px;\">\n","                        <strong>Parameter Name:</strong><br>\n","                        <span style=\"color: #0066cc; font-size: 14px;\">{current_param}</span>\n","                    </div>\n","                    <div style=\"margin-bottom: 10px;\">\n","                        <strong>Value Limits:</strong><br>\n","                        <span style=\"color: #666;\">Min: {min_val:.4f}</span><br>\n","                        <span style=\"color: #666;\">Max: {max_val:.4f}</span>\n","                    </div>\n","                </div>\n","                <div style=\"width: 48%;\">\n","                    <div style=\"margin-bottom: 10px;\">\n","                        <strong>Current Value:</strong><br>\n","                        <span style=\"color: #ff6600; font-size: 16px; font-weight: bold;\">{current_value:.4f}</span>\n","                    </div>\n","                    <div style=\"margin-bottom: 10px;\">\n","                        <strong>Associated Joints:</strong><br>\n","                        <div style=\"color: #009900; font-size: 12px;\">\n","                            {joints_str}\n","                        </div>\n","                    </div>\n","                </div>\n","            </div>\n","        </div>\n","        \"\"\"\n","\n","        self.middle_panel.value = html_content\n","\n","    def _update_all_parameters_display(self):\n","        \"\"\"Update the right panel with all parameter values in 3 columns\"\"\"\n","        # Calculate number of rows needed for 3 columns\n","        total_params = len(self.pose_parameters)\n","        rows_per_column = (total_params + 2) // 3  # Round up division\n","\n","        html_content = \"\"\"\n","        <div style=\"font-family: monospace; font-size: 11px;\">\n","            <h3 style=\"color: #333; margin-bottom: 15px; font-family: Arial;\">All Parameter Values</h3>\n","            <div style=\"display: flex; gap: 15px; justify-content: space-between;\">\n","        \"\"\"\n","\n","        # Create 3 columns\n","        for col in range(3):\n","            html_content += '<div style=\"flex: 1; min-width: 0;\">'  # min-width: 0 allows flex items to shrink\n","\n","            start_idx = col * rows_per_column\n","            end_idx = min(start_idx + rows_per_column, total_params)\n","\n","            for i in range(start_idx, end_idx):\n","                param = self.pose_parameters[i]\n","                value = parameter_values[param]\n","                color = \"#ff6600\" if value != 0.0 else \"#666\"\n","                html_content += f'<div style=\"color: {color}; margin-bottom: 2px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;\" title=\"{param}: {value:.4f}\">{i}: {value:.4f}</div>'\n","\n","            html_content += \"</div>\"\n","\n","        html_content += \"\"\"\n","            </div>\n","        </div>\n","        \"\"\"\n","        pose_parm_values = np.array(\n","            [\n","                parameter_values[parameter_name]\n","                for parameter_name in self.pose_parameters\n","            ]\n","        ).astype(np.float32)[np.newaxis, ...]\n","        rendered_html = self.render_posed_mhr(\n","            pose_parm_values, affected_joints_names=self.associted_joints\n","        )\n","\n","        self.right_panel.value = rendered_html\n","        # self.right_panel.value = html_content\n","\n","    def display(self):\n","        \"\"\"Display the complete interface\"\"\"\n","        IPython.display.display(self.main_container)\n","\n","    def get_current_values(self):\n","        \"\"\"Get current parameter values dictionary\"\"\"\n","        return parameter_values.copy()\n","\n","    def set_parameter_value(self, parameter_name, value):\n","        \"\"\"Set a specific parameter value programmatically\"\"\"\n","        if parameter_name in parameter_values:\n","            param_idx = self.pose_parameters.index(parameter_name)\n","            min_val, max_val = self.parameter_limits[param_idx]\n","\n","            # Clamp value to limits\n","            value = max(min_val, min(max_val, value))\n","\n","            self._updating = True\n","            try:\n","                parameter_values[parameter_name] = value\n","\n","                # Update slider if this is the current parameter\n","                if self.parameter_dropdown.value == parameter_name:\n","                    self.parameter_slider.value = value\n","\n","                # Update displays\n","                self._update_parameter_info()\n","                self._update_all_parameters_display()\n","                self._render_result()\n","            finally:\n","                self._updating = False\n","\n","    def _render_result(self):\n","        IPython.display.clear_output()\n","        self._update_parameter_info()\n","        self.display()\n","        pose_parm_values = np.array(\n","            [\n","                parameter_values[parameter_name]\n","                for parameter_name in self.pose_parameters\n","            ]\n","        ).astype(np.float32)[np.newaxis, ...]\n","        rendered_html = self.render_posed_mhr(\n","            pose_parm_values, affected_joints_names=self.associted_joints\n","        )\n","\n","\n","interface = BentoParameterInterface(\n","    pose_parameters=pose_parameter_names,\n","    parameter_limits=pose_parameter_limits,\n","    parameter_to_kinematic_joints=influence_mapping,\n","    render_posed_mhr=visualize_posed_mhr_model,\n",")\n","\n","interface.display()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":927,"referenced_widgets":["e871456d9a634f9187164783065f8f38","47fbe8d431754cd388b9436222dae7b1","19f3e15598c14264b43b6f1d8744c4b9","8797659f8b3e400b93b6948da6e4ff17","5c36c0cb53d64353ab937ec996bfd0ce","5248565af43142c597da644cf7920761","91cf88dddde74703b0bb1b72fd008b3a","d3923bd0b04348f392432ec1cc74ad69","ac694e18374a4c9f9ddc697aa229eb08","c833a9bfa4f24bbe86590833d3c6d9d2","137f98e86033424c8b92b738c57b468d","7612137e9bb544a68da0e4530bed3477","bb6b6c9d61b845bb81d1dcf1ebac5bfe","7fba24baffee436b8043aa7c07b4d689","4780f2f6583d428a9bf34010f266a8e0","439059252f494013ad1f81eda077f02d","fbd5c17a962542f0ad1d59d5649cb4bf","6a8777432a1f46d7b39a83c009585b13","4719a95c0a47472782125a3e2f483c16","48e2110ba9764fa0ad29a623ae7a0895","49abd3dd96a940e38da25af0ebd1e951"],"output_embedded_package_id":"1aB6In8hKNF9eyX-UYQD-9f76VLoSfU1Q"},"id":"rNT_nW3Jimwe","executionInfo":{"status":"ok","timestamp":1763524674439,"user_tz":-60,"elapsed":728,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"outputId":"7ea44501-e8d0-4e37-ffc3-1c4245730b0a","cellView":"form"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### 3. Visualize the identity space."],"metadata":{"id":"mahq6T_3Sbwn"}},{"cell_type":"code","source":["#@title 3.1 Body identity space.\n","\n","# Initialize the model parameters to be zeros.\n","rot = torch.zeros(1, 3)  # Global Rotation\n","trans = torch.zeros(1, 3)  # Translation\n","lbs_model_parms = torch.zeros(1, 198)  # Joint rotations and scales\n","params = torch.hstack((trans, rot, lbs_model_parms))\n","\n","num_pca_comp = scripted_mhr_model.get_num_identity_blendshapes()\n","body_faces = scripted_mhr_model.character_torch.mesh.faces.cpu().numpy()\n","\n","# Create animation of idenitity space.\n","meshes = visualize_blendshape_space(\n","    pc_indices = [0, 1, 2, 3, 4],\n","    model_params = params,\n","    mesh_faces=scripted_mhr_model.character_torch.mesh.faces.cpu().numpy(),\n","    num_frames = 48,\n","    num_pca_comp=num_pca_comp,\n","    face_expr_dim=72,\n","    is_expression=False\n","    )\n","\n","# Visualize the body identity shape space.\n","visualizer = ScenepicVisualization()\n","visualizer.add_meshes(\n","    meshes=meshes,\n","    mesh_names=[f\"{i+1} Princial Component\" for i in range(len(meshes[0]))],\n","    mesh_opacity=[1.0] + [0.0] * (num_pca_comp - 1)\n",")\n","print(\n","    \"Toggle layers from the top right drop-down button to switch components.\\n\"\n","    \"Click the play button in the bottom to play identity deformation animation.\\n\"\n","    )\n","visualizer.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807,"output_embedded_package_id":"1XF38M_-eST3uePy5ewOZsmoSea5S-zUc"},"cellView":"form","id":"hjOYUnsQ_Vfl","executionInfo":{"status":"ok","timestamp":1763524706600,"user_tz":-60,"elapsed":32148,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"outputId":"d81d099e-1e80-43ad-b410-6c0b371f95eb"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#@title 3.2 Head identity space.\n","\n","# Initialize the model parameters to be zeros.\n","rot = torch.zeros(1, 3)  # Global Rotation\n","trans = torch.zeros(1, 3)  # Translation\n","lbs_model_parms = torch.zeros(1, 198)  # Joint rotations and scales\n","params = torch.hstack((trans, rot, lbs_model_parms))\n","\n","num_pca_comp = scripted_mhr_model.get_num_identity_blendshapes()\n","body_faces = scripted_mhr_model.character_torch.mesh.faces.cpu().numpy()\n","\n","\n","head_mask, _ = get_head_hand_mask()\n","head_mask = head_mask > 0\n","head_face_mask = head_mask[body_faces].sum(1).astype(bool)\n","\n","# Create animation of idenitity space.\n","meshes = []\n","meshes = visualize_blendshape_space(\n","    pc_indices = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n","    model_params = params,\n","    mesh_faces=scripted_mhr_model.character_torch.mesh.faces.cpu().numpy(),\n","    num_frames = 36,\n","    num_pca_comp=num_pca_comp,\n","    face_expr_dim=72,\n","    is_expression=False,\n","    face_mask=head_face_mask\n","    )\n","\n","\n","# Visualize the body identity shape space.\n","visualizer = ScenepicVisualization()\n","visualizer.add_meshes(\n","    meshes=meshes,\n","    mesh_names=[f\"{i+1} Princial Component\" for i in range(len(meshes[0]))],\n","    mesh_opacity=[1.0] + [0.0] * (num_pca_comp - 1)\n",")\n","print(\n","    \"Toggle layers from the top right drop-down button to switch components.\\n\"\n","    \"Click the play button in the bottom to play identity deformation animation.\\n\"\n","    )\n","visualizer.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807,"output_embedded_package_id":"14i_IHkqZPa4dU_7kU-dpJ_OD0dYW0Tbp"},"id":"zxA0eTg6SqOo","executionInfo":{"status":"ok","timestamp":1763524724854,"user_tz":-60,"elapsed":18128,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"outputId":"e8b210ad-43b4-408c-eb08-adc2f9871516","cellView":"form"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#@title 3.3 Hand identity space.\n","\n","# Initialize the model parameters to be zeros.\n","rot = torch.zeros(1, 3)  # Global Rotation\n","trans = torch.zeros(1, 3)  # Translation\n","lbs_model_parms = torch.zeros(1, 198)  # Joint rotations and scales\n","params = torch.hstack((trans, rot, lbs_model_parms))\n","\n","num_pca_comp = scripted_mhr_model.get_num_identity_blendshapes()\n","body_faces = scripted_mhr_model.character_torch.mesh.faces.cpu().numpy()\n","\n","\n","_, hand_mask = get_head_hand_mask()\n","hand_mask = hand_mask > 0\n","hand_face_mask = hand_mask[body_faces].sum(1).astype(bool)\n","\n","# Create animation of idenitity space.\n","meshes = []\n","meshes = visualize_blendshape_space(\n","    pc_indices = [40, 41, 42, 43, 44],\n","    model_params = params,\n","    mesh_faces=scripted_mhr_model.character_torch.mesh.faces.cpu().numpy(),\n","    num_frames = 36,\n","    num_pca_comp=num_pca_comp,\n","    face_expr_dim=72,\n","    is_expression=False,\n","    face_mask=hand_face_mask\n","    )\n","\n","\n","# Visualize the body identity shape space.\n","visualizer = ScenepicVisualization()\n","visualizer.add_meshes(\n","    meshes=meshes,\n","    mesh_names=[f\"{i+1} Princial Component\" for i in range(len(meshes[0]))],\n","    mesh_opacity=[1.0] + [0.0] * (num_pca_comp - 1)\n",")\n","print(\n","    \"Toggle layers from the top right drop-down button to switch components.\\n\"\n","    \"Click the play button in the bottom to play identity deformation animation.\\n\"\n","    )\n","visualizer.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807,"output_embedded_package_id":"1xevFFAFouc37xdfoHQ3oVEEoyCtC2LgC"},"cellView":"form","id":"MakhXnZPfk6T","executionInfo":{"status":"ok","timestamp":1763524728190,"user_tz":-60,"elapsed":3272,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"outputId":"13c5d74b-aa90-4926-cadd-b2cb0ee019ad"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#@title 4. Visualize the expression space\n","# Initialize the model parameters to be zeros.\n","rot = torch.zeros(1, 3)  # Global Rotation\n","trans = torch.zeros(1, 3)  # Translation\n","lbs_model_parms = torch.zeros(1, 198)  # Joint rotations and scales\n","params = torch.hstack((trans, rot, lbs_model_parms))\n","\n","num_pca_comp = scripted_mhr_model.get_num_identity_blendshapes()\n","body_faces = scripted_mhr_model.character_torch.mesh.faces.cpu().numpy()\n","\n","\n","head_mask, _ = get_head_hand_mask()\n","head_mask = head_mask > 0\n","head_face_mask = head_mask[body_faces].sum(1).astype(bool)\n","\n","# Create animation of idenitity space.\n","meshes = []\n","meshes = visualize_blendshape_space(\n","    pc_indices = list(range(8)),\n","    model_params = params,\n","    mesh_faces=scripted_mhr_model.character_torch.mesh.faces.cpu().numpy(),\n","    num_frames = 36,\n","    num_pca_comp=num_pca_comp,\n","    face_expr_dim=72,\n","    is_expression=True,\n","    face_mask=head_face_mask\n","    )\n","\n","\n","# Visualize the body identity shape space.\n","visualizer = ScenepicVisualization()\n","visualizer.add_meshes(\n","    meshes=meshes,\n","    mesh_names=[f\"{i+1} Princial Component\" for i in range(len(meshes[0]))],\n","    mesh_opacity=[1.0] + [0.0] * (num_pca_comp - 1)\n",")\n","print(\n","    \"Toggle layers from the top right drop-down button to switch components.\\n\"\n","    \"Click the play button in the bottom to play identity deformation animation.\\n\"\n","    )\n","visualizer.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807,"output_embedded_package_id":"1Ko4v_xUrE0S3LYg7gZBdpeyfISbaNkmF"},"cellView":"form","id":"M2VpJ5jHlVEO","executionInfo":{"status":"ok","timestamp":1763524743777,"user_tz":-60,"elapsed":15569,"user":{"displayName":"Jinlong YANG","userId":"11895603835275502765"}},"outputId":"3871013e-f20a-438f-fa56-6d41b2fac6fd"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}